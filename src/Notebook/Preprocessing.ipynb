{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "262a8cc4-c595-4c4f-82d5-8f5cda5b87e2",
   "metadata": {},
   "source": [
    "# Organising the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aaa012a-5525-4472-a944-df1bd2f11806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ SERM_P1_WOD_1660_LeichPredigt.xml → 1650-1700/Sermons\n",
      "✓ SERM_P3_OOD_1792_Sonntagen.xml → 1750-1800/Sermons\n",
      "✓ LEGA_P1_WOD_1654_HoffgerichtsOrdnung.xml → 1650-1700/Legal\n",
      "✓ SCIE_P2_WOD_1741_Erden.xml → 1700-1750/Scientific\n",
      "✓ HUMA_P1_NoD_1667_Ratseburg.xml → 1650-1700/Humanities\n",
      "✓ LEGA_P3_NoD_1751_FeuerOrdnung.xml → 1750-1800/Legal\n",
      "✓ DRAM_P1_OOD_1675_Pirrus.xml → 1650-1700/Drama\n",
      "✓ SCIE_P1_OOD_1681_CometenGespoetts.xml → 1650-1700/Scientific\n",
      "✓ NARR_P1_OMD_1671_Ruebezahl.xml → 1650-1700/Narrative\n",
      "✓ HUMA_P1_WMD_1692_Christus.xml → 1650-1700/Humanities\n",
      "✓ HUMA_P3_WMD_1772_Baukunst.xml → 1750-1800/Humanities\n",
      "✓ SERM_P2_OMD_1715_Beerdigung.xml → 1700-1750/Sermons\n",
      "✓ SCIE_P3_NoD_1799_Gasarten.xml → 1750-1800/Scientific\n",
      "✓ SCIE_P2_WMD_1744_SelbstArtzt.xml → 1700-1750/Scientific\n",
      "✓ SERM_P3_OMD_1760_Folgen.xml → 1750-1800/Sermons\n",
      "✓ SERM_P3_WOD_1792_Hegel.xml → 1750-1800/Sermons\n",
      "✓ NEWS_P2_OOD_1702_muenchen2.xml → 1700-1750/Newspapers\n",
      "✓ DRAM_P2_WOD_1748_Hoelle.xml → 1700-1750/Drama\n",
      "✓ NARR_P2_NoD_1715_Africa.xml → 1700-1750/Narrative\n",
      "✓ SERM_P2_WMD_1702_Leben.xml → 1700-1750/Sermons\n",
      "✓ SERM_P1_OMD_1680_Balcken.xml → 1650-1700/Sermons\n",
      "✓ HUMA_P1_OOD_1680_MercksWienn.xml → 1650-1700/Humanities\n",
      "✓ HUMA_P1_NoD_1663_HaubtSprache.xml → 1650-1700/Humanities\n",
      "✓ SERM_P1_WMD_1674_Trost.xml → 1650-1700/Sermons\n",
      "✓ NEWS_P3_OMD_1769_erfurt.xml → 1750-1800/Newspapers\n",
      "✓ LEGA_P2_WOD_1738_Constantz.xml → 1700-1750/Legal\n",
      "✓ NEWS_P1_OOD_1684_muenchmerc.xml → 1650-1700/Newspapers\n",
      "✓ LEGA_P2_NoD_1707_Reglement.xml → 1700-1750/Legal\n",
      "✓ NARR_P3_OOD_1789_PeterProsch.xml → 1750-1800/Narrative\n",
      "✓ DRAM_P3_NoD_1764_Salomo.xml → 1750-1800/Drama\n",
      "✓ HUMA_P1_OMD_1654_Rosetum.xml → 1650-1700/Humanities\n",
      "✓ DRAM_P1_OMD_1657_Cardenio.xml → 1650-1700/Drama\n",
      "✓ DRAM_P3_OOD_1764_Maegera.xml → 1750-1800/Drama\n",
      "✓ DRAM_P1_WOD_1687_Joseph.xml → 1650-1700/Drama\n",
      "✓ NEWS_P2_NoD_1735_berlin.xml → 1700-1750/Newspapers\n",
      "✓ LEGA_P2_OOD_1704_OrdnungNuernberg.xml → 1700-1750/Legal\n",
      "✓ NEWS_P2_OOD_1702_muenchen1.xml → 1700-1750/Newspapers\n",
      "✓ SCIE_P3_WOD_1774_Hygrometrie.xml → 1750-1800/Scientific\n",
      "✓ SCIE_P1_NoD_1680_ConsiliumMedicum.xml → 1650-1700/Scientific\n",
      "✓ NARR_P1_NoD_1659_Herkules.xml → 1650-1700/Narrative\n",
      "✓ NARR_P2_OMD_1731_Seefahrer.xml → 1700-1750/Narrative\n",
      "✓ LEGA_P2_OMD_1709_WaeysenOrdnung.xml → 1700-1750/Legal\n",
      "✓ HUMA_P1_OMD_1685_ChristenStat.xml → 1650-1700/Humanities\n",
      "✓ DRAM_P3_NoD_1767_Minna.xml → 1750-1800/Drama\n",
      "✓ NEWS_P1_OMD_1666_leipzig2.xml → 1650-1700/Newspapers\n",
      "✓ LEGA_P3_OOD_1769_Theresiana.xml → 1750-1800/Legal\n",
      "✓ SCIE_P1_WMD_1676_ArtzneyBuch.xml → 1650-1700/Scientific\n",
      "✓ NARR_P1_WOD_1689_Miranten.xml → 1650-1700/Narrative\n",
      "✓ NEWS_P3_WOD_1784_freiburg2.xml → 1750-1800/Newspapers\n",
      "✓ HUMA_P3_WOD_1784_Weibs.xml → 1750-1800/Humanities\n",
      "✓ SERM_P1_WOD_1683_TrostPredigt.xml → 1650-1700/Sermons\n",
      "✓ SCIE_P2_OMD_1737_Medica.xml → 1700-1750/Scientific\n",
      "✓ LEGA_P2_WOD_1729_WechselRecht.xml → 1700-1750/Legal\n",
      "✓ DRAM_P1_WOD_1663_Carle.xml → 1650-1700/Drama\n",
      "✓ LEGA_P1_WOD_1698_LandsOrdnung.xml → 1650-1700/Legal\n",
      "✓ SERM_P3_OOD_1782_Erloeser.xml → 1750-1800/Sermons\n",
      "✓ LEGA_P3_WMD_1772_RegimentsVerfassung.xml → 1750-1800/Legal\n",
      "✓ HUMA_P2_NoD_1737_Koenigstein.xml → 1700-1750/Humanities\n",
      "✓ LEGA_P1_WOD_1683_Ulm.xml → 1650-1700/Legal\n",
      "✓ SERM_P3_NoD_1798_LetztePredigt.xml → 1750-1800/Sermons\n",
      "✓ SERM_P3_WOD_1751_DreiKoenig.xml → 1750-1800/Sermons\n",
      "✓ DRAM_P2_WMD_1745_Zuegellose.xml → 1700-1750/Drama\n",
      "✓ SCIE_P1_OOD_1689_PferdKunst.xml → 1650-1700/Scientific\n",
      "✓ NARR_P3_OOD_1796_Quintus.xml → 1750-1800/Narrative\n",
      "✓ NEWS_P1_OMD_1666_leipzig1.xml → 1650-1700/Newspapers\n",
      "✓ NARR_P2_WMD_1750_Teutsche.xml → 1700-1750/Narrative\n",
      "✓ DRAM_P2_OOD_1733_Ciro.xml → 1700-1750/Drama\n",
      "✓ NARR_P2_OOD_1734_TaendlMarckt.xml → 1700-1750/Narrative\n",
      "✓ HUMA_P1_WMD_1699_KetzerHistorie.xml → 1650-1700/Humanities\n",
      "✓ LEGA_P3_OOD_1750_HofRathsOrdnung.xml → 1750-1800/Legal\n",
      "✓ DRAM_P1_NoD_1673_Leonilda.xml → 1650-1700/Drama\n",
      "✓ NEWS_P3_WOD_1784_freiburg1.xml → 1750-1800/Newspapers\n",
      "✓ NARR_P3_WMD_1782_Fragmente.xml → 1750-1800/Narrative\n",
      "✓ NARR_P1_WMD_1664_Levante.xml → 1650-1700/Narrative\n",
      "✓ SERM_P3_OMD_1790_Unruhen.xml → 1750-1800/Sermons\n",
      "✓ SERM_P1_OOD_1663_Amaradvlcis.xml → 1650-1700/Sermons\n",
      "✓ NEWS_P1_WOD_1662_strassburg1.xml → 1650-1700/Newspapers\n",
      "✓ SCIE_P2_WOD_1720_FangSchlaeussen.xml → 1700-1750/Scientific\n",
      "✓ LEGA_P2_NoD_1724_StadtRecht.xml → 1700-1750/Legal\n",
      "✓ SCIE_P1_OMD_1700_BergBau.xml → 1650-1700/Scientific\n",
      "✓ SCIE_P1_OMD_1664_StraussStern.xml → 1650-1700/Scientific\n",
      "✓ SERM_P3_OMD_1756_Trost.xml → 1750-1800/Sermons\n",
      "✓ SCIE_P3_WOD_1787_Botanik.xml → 1750-1800/Scientific\n",
      "✓ SCIE_P2_NoD_1734_Barometer.xml → 1700-1750/Scientific\n",
      "✓ NARR_P2_WOD_1724_JungferRobinsone.xml → 1700-1750/Narrative\n",
      "✓ HUMA_P2_OMD_1725_Hass.xml → 1700-1750/Humanities\n",
      "✓ SERM_P2_WMD_1721_HeilBronnen.xml → 1700-1750/Sermons\n",
      "✓ LEGA_P2_WMD_1724_GesetzBuch.xml → 1700-1750/Legal\n",
      "✓ NEWS_P2_WMD_1701_hanau2.xml → 1700-1750/Newspapers\n",
      "✓ NEWS_P3_NoD_1786_wolfenbuettel1.xml → 1750-1800/Newspapers\n",
      "✓ DRAM_P2_WMD_1742_Bookesbeutel.xml → 1700-1750/Drama\n",
      "✓ SERM_P1_OMD_1680_SursumDeosum.xml → 1650-1700/Sermons\n",
      "✓ NEWS_P3_WMD_1784_mannheim.xml → 1750-1800/Newspapers\n",
      "✓ HUMA_P2_WOD_1744_Pfaltz.xml → 1700-1750/Humanities\n",
      "✓ NEWS_P1_WOD_1685_lindau.xml → 1650-1700/Newspapers\n",
      "✓ NEWS_P1_WOD_1662_strassburg2.xml → 1650-1700/Newspapers\n",
      "✓ SERM_P2_NoD_1715_Klugheit.xml → 1700-1750/Sermons\n",
      "✓ HUMA_P1_WOD_1698_Mythoscopia.xml → 1650-1700/Humanities\n",
      "✓ SERM_P2_WOD_1739_Kranckentrost.xml → 1700-1750/Sermons\n",
      "✓ HUMA_P1_OOD_1689_Crain.xml → 1650-1700/Humanities\n",
      "✓ DRAM_P1_WMD_1670_Comoedianten.xml → 1650-1700/Drama\n",
      "✓ NEWS_P3_WMD_1797_hanau.xml → 1750-1800/Newspapers\n",
      "✓ LEGA_P3_NoD_1757_Rostock.xml → 1750-1800/Legal\n",
      "✓ NARR_P1_NoD_1658_Morgenlaendisch.xml → 1650-1700/Narrative\n",
      "✓ DRAM_P2_OMD_1736_Fischbein.xml → 1700-1750/Drama\n",
      "✓ SERM_P2_NoD_1730_JubelFeste.xml → 1700-1750/Sermons\n",
      "✓ DRAM_P1_NoD_1700_Freyheit.xml → 1650-1700/Drama\n",
      "✓ NEWS_P2_OMD_1724_halle.xml → 1700-1750/Newspapers\n",
      "✓ NEWS_P2_WMD_1701_hanau1.xml → 1700-1750/Newspapers\n",
      "✓ LEGA_P2_OOD_1719_Privilegien.xml → 1700-1750/Legal\n",
      "✓ HUMA_P2_OOD_1707_HundertNarren.xml → 1700-1750/Humanities\n",
      "✓ DRAM_P3_WMD_1787_Verbrechen.xml → 1750-1800/Drama\n",
      "✓ NARR_P3_NoD_1786_Muenchhausen.xml → 1750-1800/Narrative\n",
      "✓ NEWS_P3_NoD_1786_wolfenbuettel2.xml → 1750-1800/Newspapers\n",
      "✓ SERM_P3_WOD_1790_Strassburg.xml → 1750-1800/Sermons\n",
      "✓ DRAM_P3_OMD_1788_Egmont.xml → 1750-1800/Drama\n",
      "✓ NARR_P3_WOD_1771_Usong.xml → 1750-1800/Narrative\n",
      "✓ LEGA_P1_OOD_1659_SchulOrdnung.xml → 1650-1700/Legal\n",
      "✓ SERM_P3_WMD_1774_Gewohnheit.xml → 1750-1800/Sermons\n",
      "✓ DRAM_P3_OMD_1775_LeidendeWeib.xml → 1750-1800/Drama\n",
      "✓ LEGA_P1_OOD_1657_Wildtfang.xml → 1650-1700/Legal\n",
      "✓ NARR_P3_WMD_1783_MoralischeErzaehlungen.xml → 1750-1800/Narrative\n",
      "✓ SCIE_P3_WMD_1777_Logik.xml → 1750-1800/Scientific\n",
      "✓ NARR_P1_WOD_1672_Melcher.xml → 1650-1700/Narrative\n",
      "✓ HUMA_P2_WMD_1737_Curiositaeten.xml → 1700-1750/Humanities\n",
      "✓ DRAM_P2_WOD_1702_Helvetia.xml → 1700-1750/Drama\n",
      "✓ DRAM_P2_OOD_1725_Venceslao.xml → 1700-1750/Drama\n",
      "✓ NARR_P2_WMD_1716_Fleurie.xml → 1700-1750/Narrative\n",
      "✓ NEWS_P2_OMD_1722_leipzig2.xml → 1700-1750/Newspapers\n",
      "✓ HUMA_P3_WOD_1795_Dichtung.xml → 1750-1800/Humanities\n",
      "✓ HUMA_P1_WOD_1686_Betrachtung.xml → 1650-1700/Humanities\n",
      "✓ NEWS_P1_NoD_1698_altona.xml → 1650-1700/Newspapers\n",
      "✓ NEWS_P2_NoD_1740_berlin1.xml → 1700-1750/Newspapers\n",
      "✓ NARR_P1_WMD_1696_Schelmuffsky.xml → 1650-1700/Narrative\n",
      "✓ NEWS_P3_WOD_1798_tuebingen.xml → 1750-1800/Newspapers\n",
      "✓ NEWS_P2_WMD_1750_frankfurt.xml → 1700-1750/Newspapers\n",
      "✓ SCIE_P3_OOD_1786_Polizey.xml → 1750-1800/Scientific\n",
      "✓ DRAM_P2_NoD_1707_SchaeferSpiel.xml → 1700-1750/Drama\n",
      "✓ LEGA_P3_OMD_1767_ProcessOrdnung.xml → 1750-1800/Legal\n",
      "✓ HUMA_P1_OOD_1690_Proteus.xml → 1650-1700/Humanities\n",
      "✓ NEWS_P1_OMD_1683_breslau.xml → 1650-1700/Newspapers\n",
      "✓ DRAM_P1_OMD_1661_Cleopatra.xml → 1650-1700/Drama\n",
      "✓ SERM_P1_NoD_1677_LeichSermon.xml → 1650-1700/Sermons\n",
      "✓ HUMA_P3_NoD_1762_Kreuzzuege.xml → 1750-1800/Humanities\n",
      "✓ NEWS_P2_NoD_1702_hamburg.xml → 1700-1750/Newspapers\n",
      "✓ DRAM_P1_WMD_1662_Tomyris.xml → 1650-1700/Drama\n",
      "✓ LEGA_P3_OMD_1777_MuehlenOrdnung.xml → 1750-1800/Legal\n",
      "✓ SERM_P1_OMD_1672_Advent.xml → 1650-1700/Sermons\n",
      "✓ DRAM_P3_WOD_1762_Evander.xml → 1750-1800/Drama\n",
      "✓ SCIE_P1_WOD_1693_Kranckheit.xml → 1650-1700/Scientific\n",
      "✓ LEGA_P1_NoD_1657_Luebeck.xml → 1650-1700/Legal\n",
      "✓ NEWS_P2_OMD_1722_leipzig1.xml → 1700-1750/Newspapers\n",
      "✓ SCIE_P3_WMD_1781_Forstwissenschaft.xml → 1750-1800/Scientific\n",
      "✓ NEWS_P2_NoD_1740_berlin2.xml → 1700-1750/Newspapers\n",
      "✓ DRAM_P1_OOD_1682_Abraham.xml → 1650-1700/Drama\n",
      "✓ SERM_P2_OMD_1734_Evangelisch.xml → 1700-1750/Sermons\n",
      "✓ LEGA_P3_WMD_1756_StaatsArchiv.xml → 1750-1800/Legal\n",
      "✓ NEWS_P3_WMD_1793_mainz.xml → 1750-1800/Newspapers\n",
      "✓ SCIE_P3_WOD_1780_Instrument.xml → 1750-1800/Scientific\n",
      "✓ SERM_P2_NoD_1715_Seeligkeit.xml → 1700-1750/Sermons\n",
      "✓ HUMA_P1_WOD_1662_Musurgia.xml → 1650-1700/Humanities\n",
      "✓ NARR_P3_WOD_1766_Agathon.xml → 1750-1800/Narrative\n",
      "✓ NARR_P1_OMD_1689_Arminius.xml → 1650-1700/Narrative\n",
      "✓ NARR_P1_OOD_1669_Aramena.xml → 1650-1700/Narrative\n",
      "✓ NEWS_P1_OOD_1679_nuernberg1.xml → 1650-1700/Newspapers\n",
      "✓ SERM_P3_WMD_1780_LottoSucht.xml → 1750-1800/Sermons\n",
      "✓ SERM_P3_OOD_1751_Elisabetha.xml → 1750-1800/Sermons\n",
      "✓ SERM_P3_NoD_1765_Trauerrede.xml → 1750-1800/Sermons\n",
      "✓ DRAM_P2_NoD_1711_Croesus.xml → 1700-1750/Drama\n",
      "✓ NEWS_P1_OMD_1684_breslau.xml → 1650-1700/Newspapers\n",
      "✓ SCIE_P3_NoD_1775_Chemie.xml → 1750-1800/Scientific\n",
      "✓ DRAM_P1_OMD_1683_Masaniello.xml → 1650-1700/Drama\n",
      "✓ SCIE_P1_WMD_1687_ArtzneyKunst.xml → 1650-1700/Scientific\n",
      "✓ SCIE_P2_NoD_1736_Anweisung.xml → 1700-1750/Scientific\n",
      "✓ SERM_P1_WMD_1699_Solms.xml → 1650-1700/Sermons\n",
      "✓ SCIE_P2_OOD_1745_Mathematicus.xml → 1700-1750/Scientific\n",
      "✓ LEGA_P3_WOD_1791_Muenze.xml → 1750-1800/Legal\n",
      "✓ NARR_P3_NoD_1796_Siebenkaes.xml → 1750-1800/Narrative\n",
      "✓ HUMA_P1_WMD_1674_BilderSchatz.xml → 1650-1700/Humanities\n",
      "✓ SCIE_P2_WMD_1714_Kleinod.xml → 1700-1750/Scientific\n",
      "✓ HUMA_P2_OOD_1704_WasserKunst.xml → 1700-1750/Humanities\n",
      "✓ SCIE_P1_WOD_1663_KunstSpiegel.xml → 1650-1700/Scientific\n",
      "✓ LEGA_P3_OMD_1784_Erbstatuten.xml → 1750-1800/Legal\n",
      "✓ SCIE_P1_OMD_1672_Handwercke.xml → 1650-1700/Scientific\n",
      "✓ LEGA_P3_NoD_1796_Landtage.xml → 1750-1800/Legal\n",
      "✓ NARR_P2_OMD_1738_LebensBeschreibung.xml → 1700-1750/Narrative\n",
      "✓ NARR_P3_OMD_1776_Zerbin.xml → 1750-1800/Narrative\n",
      "✓ DRAM_P3_OMD_1774_Hofmeister.xml → 1750-1800/Drama\n",
      "✓ NEWS_P1_OOD_1679_nuernberg2.xml → 1650-1700/Newspapers\n",
      "✓ SCIE_P2_WMD_1702_Armuth.xml → 1700-1750/Scientific\n",
      "✓ SCIE_P3_OMD_1781_Chymie.xml → 1750-1800/Scientific\n",
      "✓ HUMA_P1_NoD_1674_NaturalienKammer.xml → 1650-1700/Humanities\n",
      "✓ NARR_P1_OOD_1667_Simplicissimus.xml → 1650-1700/Narrative\n",
      "✓ SCIE_P3_OOD_1780_ZeichenInstruments.xml → 1750-1800/Scientific\n",
      "✓ LEGA_P2_WOD_1711_HalsGericht.xml → 1700-1750/Legal\n",
      "✓ SERM_P2_OOD_1709_Orgel.xml → 1700-1750/Sermons\n",
      "✓ SCIE_P2_OOD_1705_WerckSchul.xml → 1700-1750/Scientific\n",
      "✓ DRAM_P3_NoD_1776_Zwillinge.xml → 1750-1800/Drama\n",
      "✓ LEGA_P2_WMD_1733_Heyrathen.xml → 1700-1750/Legal\n",
      "✓ NEWS_P3_OOD_1780_wien.xml → 1750-1800/Newspapers\n",
      "✓ LEGA_P1_NoD_1673_BergOrdnung.xml → 1650-1700/Legal\n",
      "✓ DRAM_P1_WMD_1668_ChristRuehmendes.xml → 1650-1700/Drama\n",
      "✓ LEGA_P2_OMD_1723_JurisMilitaris.xml → 1700-1750/Legal\n",
      "✓ DRAM_P3_OOD_1798_Donauweibchen.xml → 1750-1800/Drama\n",
      "✓ NEWS_P3_WOD_1781_heilbronn.xml → 1750-1800/Newspapers\n",
      "✓ SCIE_P2_WOD_1708_WunderbarenWelt.xml → 1700-1750/Scientific\n",
      "✓ NEWS_P2_WOD_1722_zuerich.xml → 1700-1750/Newspapers\n",
      "✓ NEWS_P3_OOD_1791_bayreuth.xml → 1750-1800/Newspapers\n",
      "✓ NARR_P2_OOD_1703_Narrennest.xml → 1700-1750/Narrative\n",
      "✓ HUMA_P3_WMD_1789_Italien.xml → 1750-1800/Humanities\n",
      "✓ HUMA_P2_OOD_1731_AntiquitaetenSchatz.xml → 1700-1750/Humanities\n",
      "✓ SERM_P1_NoD_1666_Erbteil.xml → 1650-1700/Sermons\n",
      "✓ SERM_P1_WOD_1654_Eytelkeit.xml → 1650-1700/Sermons\n",
      "✓ NEWS_P3_OMD_1789_gotha.xml → 1750-1800/Newspapers\n",
      "✓ NARR_P2_WMD_1742_RedlicheMann.xml → 1700-1750/Narrative\n",
      "✓ SERM_P2_WOD_1730_SeelenLiecht.xml → 1700-1750/Sermons\n",
      "✓ LEGA_P2_WMD_1720_VatterMord.xml → 1700-1750/Legal\n",
      "✓ NEWS_P1_OOD_1659_muenchen2.xml → 1650-1700/Newspapers\n",
      "✓ DRAM_P3_WMD_1780_Hausvater.xml → 1750-1800/Drama\n",
      "✓ NEWS_P1_OOD_1659_muenchmerc.xml → 1650-1700/Newspapers\n",
      "✓ NEWS_P3_OOD_1790_erlangen.xml → 1750-1800/Newspapers\n",
      "✓ HUMA_P1_OMD_1680_Bericht.xml → 1650-1700/Humanities\n",
      "✓ LEGA_P2_NoD_1700_Braunschweig.xml → 1700-1750/Legal\n",
      "✓ HUMA_P3_OOD_1792_Alterthuemer.xml → 1750-1800/Humanities\n",
      "✓ SCIE_P1_WMD_1680_Epidemica.xml → 1650-1700/Scientific\n",
      "✓ NEWS_P1_WMD_1662_koeln.xml → 1650-1700/Newspapers\n",
      "✓ LEGA_P1_WMD_1698_BergkRecht.xml → 1650-1700/Legal\n",
      "✓ NARR_P3_OOD_1787_Aglais.xml → 1750-1800/Narrative\n",
      "✓ NARR_P3_OMD_1782_Volksmaerchen.xml → 1750-1800/Narrative\n",
      "✓ HUMA_P3_NoD_1772_Ursprung.xml → 1750-1800/Humanities\n",
      "✓ LEGA_P1_OOD_1700_GesetzNuernberg.xml → 1650-1700/Legal\n",
      "✓ SCIE_P2_NoD_1744_Cometen.xml → 1700-1750/Scientific\n",
      "✓ NARR_P2_OOD_1715_HeldenGeschichte.xml → 1700-1750/Narrative\n",
      "✓ NEWS_P1_WOD_1681_zuerich.xml → 1650-1700/Newspapers\n",
      "✓ SERM_P2_OOD_1700_FeyerTag.xml → 1700-1750/Sermons\n",
      "✓ HUMA_P3_OOD_1774_Emil.xml → 1750-1800/Humanities\n",
      "✓ NEWS_P2_OOD_1712_wien.xml → 1700-1750/Newspapers\n",
      "✓ NEWS_P2_OOD_1713_wien.xml → 1700-1750/Newspapers\n",
      "✓ NARR_P2_WOD_1744_Fabeln.xml → 1700-1750/Narrative\n",
      "✓ NEWS_P3_OMD_1784_gotha.xml → 1750-1800/Newspapers\n",
      "✓ LEGA_P3_OOD_1752_Gerichtbarkeit.xml → 1750-1800/Legal\n",
      "✓ NARR_P3_OMD_1774_Werther.xml → 1750-1800/Narrative\n",
      "✓ DRAM_P1_OOD_1682_LiebesSig.xml → 1650-1700/Drama\n",
      "✓ LEGA_P1_OMD_1680_Dreszden.xml → 1650-1700/Legal\n",
      "✓ NEWS_P1_OOD_1659_muenchen1.xml → 1650-1700/Newspapers\n",
      "✓ NEWS_P3_NoD_1796_stettin.xml → 1750-1800/Newspapers\n",
      "✓ SCIE_P2_OOD_1722_NordScheines.xml → 1700-1750/Scientific\n",
      "✓ DRAM_P2_OOD_1749_Schaeferinsel.xml → 1700-1750/Drama\n",
      "✓ LEGA_P3_WOD_1769_ZunftOrdnungen.xml → 1750-1800/Legal\n",
      "✓ HUMA_P3_NoD_1788_Menschen.xml → 1750-1800/Humanities\n",
      "✓ NEWS_P3_OMD_1790_gotha.xml → 1750-1800/Newspapers\n",
      "✓ SCIE_P1_WOD_1665_Cometen.xml → 1650-1700/Scientific\n",
      "✓ NEWS_P1_NoD_1666_berlin2.xml → 1650-1700/Newspapers\n",
      "✓ NARR_P2_NoD_1706_SatyrischerRoman.xml → 1700-1750/Narrative\n",
      "✓ DRAM_P1_WOD_1699_LiebesStreit.xml → 1650-1700/Drama\n",
      "✓ SCIE_P3_OMD_1781_Akademie.xml → 1750-1800/Scientific\n",
      "✓ NARR_P3_WOD_1797_Hyperion.xml → 1750-1800/Narrative\n",
      "✓ HUMA_P2_WMD_1739_Stollberg.xml → 1700-1750/Humanities\n",
      "✓ NARR_P1_WMD_1696_DerEdelmann.xml → 1650-1700/Narrative\n",
      "✓ SCIE_P1_NoD_1684_Durchfall.xml → 1650-1700/Scientific\n",
      "✓ SCIE_P3_OMD_1778_MineralogischeGeographie.xml → 1750-1800/Scientific\n",
      "✓ SCIE_P2_OMD_1717_Materialist.xml → 1700-1750/Scientific\n",
      "✓ SERM_P1_OOD_1686_KlagseufftzendesAch.xml → 1650-1700/Sermons\n",
      "✓ HUMA_P2_NoD_1720_Remarques.xml → 1700-1750/Humanities\n",
      "✓ NEWS_P1_WMD_1671_frankfurt1.xml → 1650-1700/Newspapers\n",
      "✓ HUMA_P2_WOD_1740_Poesie.xml → 1700-1750/Humanities\n",
      "✓ SERM_P2_WOD_1708_Zotten.xml → 1700-1750/Sermons\n",
      "✓ NEWS_P3_NoD_1798_danzig.xml → 1750-1800/Newspapers\n",
      "✓ NEWS_P1_NoD_1666_berlin1.xml → 1650-1700/Newspapers\n",
      "✓ LEGA_P3_WMD_1792_Reichshofrath.xml → 1750-1800/Legal\n",
      "✓ SERM_P1_NoD_1690_WilleGottes.xml → 1650-1700/Sermons\n",
      "✓ SERM_P1_WMD_1662_Funeralia.xml → 1650-1700/Sermons\n",
      "✓ SCIE_P1_NoD_1672_Prognosticis.xml → 1650-1700/Scientific\n",
      "✓ NARR_P1_NoD_1682_Mandorell.xml → 1650-1700/Narrative\n",
      "✓ SERM_P2_WMD_1743_TrostPredigt.xml → 1700-1750/Sermons\n",
      "✓ DRAM_P2_WMD_1743_DieGeistlichen.xml → 1700-1750/Drama\n",
      "✓ SERM_P3_NoD_1770_Gottesdienst.xml → 1750-1800/Sermons\n",
      "✓ HUMA_P2_WMD_1748_Samuel.xml → 1700-1750/Humanities\n",
      "✓ SERM_P2_OOD_1728_Verstellte.xml → 1700-1750/Sermons\n",
      "✓ NEWS_P2_OOD_1744_graz.xml → 1700-1750/Newspapers\n",
      "✓ NEWS_P1_WMD_1699_koeln.xml → 1650-1700/Newspapers\n",
      "✓ LEGA_P1_WMD_1700_LandRecht.xml → 1650-1700/Legal\n",
      "✓ DRAM_P3_WMD_1773_Goetz.xml → 1750-1800/Drama\n",
      "✓ NEWS_P1_NoD_1673_hamburg.xml → 1650-1700/Newspapers\n",
      "✓ SCIE_P1_OOD_1665_Feldmessen.xml → 1650-1700/Scientific\n",
      "✓ NARR_P2_NoD_1709_OstIndien.xml → 1700-1750/Narrative\n",
      "✓ HUMA_P3_WMD_1777_Homburg.xml → 1750-1800/Humanities\n",
      "✓ DRAM_P2_OMD_1732_Cato.xml → 1700-1750/Drama\n",
      "✓ NARR_P1_WOD_1682_Feuermaeuer.xml → 1650-1700/Narrative\n",
      "✓ NEWS_P1_WMD_1671_frankfurt2.xml → 1650-1700/Newspapers\n",
      "✓ SERM_P3_WMD_1780_Feuersbrunst.xml → 1750-1800/Sermons\n",
      "✓ SERM_P1_OOD_1660_EinweihungsPredigt.xml → 1650-1700/Sermons\n",
      "✓ LEGA_P1_WMD_1694_RathsSatzung.xml → 1650-1700/Legal\n",
      "✓ LEGA_P2_OMD_1710_ReichsArchiv.xml → 1700-1750/Legal\n",
      "✓ HUMA_P2_WOD_1741_Antiquitaeten.xml → 1700-1750/Humanities\n",
      "✓ NARR_P3_NoD_1790_AntonReiser.xml → 1750-1800/Narrative\n",
      "✓ DRAM_P2_OMD_1747_Schwestern.xml → 1700-1750/Drama\n",
      "✓ NARR_P1_OMD_1700_Banise.xml → 1650-1700/Narrative\n",
      "✓ NEWS_P2_OMD_1744_erfurt2.xml → 1700-1750/Newspapers\n",
      "✓ NEWS_P2_WMD_1701_frankfurt.xml → 1700-1750/Newspapers\n",
      "✓ DRAM_P3_WOD_1781_Raeuber.xml → 1750-1800/Drama\n",
      "✓ NEWS_P1_WOD_1689_lindau.xml → 1650-1700/Newspapers\n",
      "✓ SCIE_P2_OMD_1731_HarnRuhr.xml → 1700-1750/Scientific\n",
      "✓ HUMA_P2_NoD_1739_MusicalischInterval.xml → 1700-1750/Humanities\n",
      "✓ LEGA_P1_NoD_1695_Duesseldorff.xml → 1650-1700/Legal\n",
      "✓ HUMA_P3_OMD_1777_Dichtkunst.xml → 1750-1800/Humanities\n",
      "✓ DRAM_P2_WOD_1737_Verehrung.xml → 1700-1750/Drama\n",
      "✓ LEGA_P3_WOD_1787_Cameralrecht.xml → 1750-1800/Legal\n",
      "✓ NEWS_P2_WOD_1749_loerrach2.xml → 1700-1750/Newspapers\n",
      "✓ DRAM_P1_NoD_1699_Euridice.xml → 1650-1700/Drama\n",
      "✓ NARR_P2_WOD_1746_Muetze.xml → 1700-1750/Narrative\n",
      "✓ NEWS_P1_OMD_1687_leipzig.xml → 1650-1700/Newspapers\n",
      "✓ HUMA_P3_OMD_1798_Sondershausen.xml → 1750-1800/Humanities\n",
      "✓ HUMA_P3_WOD_1768_Roemer.xml → 1750-1800/Humanities\n",
      "✓ HUMA_P3_OOD_1778_Pons.xml → 1750-1800/Humanities\n",
      "✓ NEWS_P2_WOD_1723_augsburg1.xml → 1700-1750/Newspapers\n",
      "✓ NARR_P1_OOD_1682_Winternaechte.xml → 1650-1700/Narrative\n",
      "✓ SCIE_P3_OOD_1788_Chimie.xml → 1750-1800/Scientific\n",
      "✓ NEWS_P2_OMD_1744_erfurt1.xml → 1700-1750/Newspapers\n",
      "✓ DRAM_P3_OOD_1782_Serail.xml → 1750-1800/Drama\n",
      "✓ HUMA_P2_OMD_1717_DienstMaegde.xml → 1700-1750/Humanities\n",
      "✓ LEGA_P1_OMD_1659_Hexen.xml → 1650-1700/Legal\n",
      "✓ DRAM_P3_WOD_1783_Elfride.xml → 1750-1800/Drama\n",
      "✓ LEGA_P1_OMD_1674_BergOrdnung.xml → 1650-1700/Legal\n",
      "✓ NEWS_P1_WMD_1663_koeln.xml → 1650-1700/Newspapers\n",
      "✓ SCIE_P3_NoD_1761_Menschlich.xml → 1750-1800/Scientific\n",
      "✓ LEGA_P2_OOD_1709_Promptuarii.xml → 1700-1750/Legal\n",
      "✓ NEWS_P2_WOD_1749_loerrach1.xml → 1700-1750/Newspapers\n",
      "✓ NARR_P2_OMD_1708_Affecten.xml → 1700-1750/Narrative\n",
      "✓ SCIE_P3_WMD_1753_ProbierSteins.xml → 1750-1800/Scientific\n",
      "✓ HUMA_P3_OMD_1774_Roman.xml → 1750-1800/Humanities\n",
      "✓ NARR_P3_WMD_1775_Bacchidon.xml → 1750-1800/Narrative\n",
      "✓ DRAM_P2_NoD_1749_AlteJungfer.xml → 1700-1750/Drama\n",
      "✓ SERM_P2_OMD_1706_GedaechtnisPredigt.xml → 1700-1750/Sermons\n",
      "✓ NEWS_P2_WOD_1723_augsburg2.xml → 1700-1750/Newspapers\n",
      "✓ HUMA_P2_OMD_1729_Biedermann.xml → 1700-1750/Humanities\n",
      "\n",
      "📊 Report saved to: /Users/rohan/Downloads/2544/organized_germanc/organization_report.txt\n",
      "\n",
      "🎉 Organization complete!\n",
      "📁 Organized 336 files\n",
      "❌ 0 errors\n",
      "📊 Check organization_report.txt for details\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "class GerManCOrganizer:\n",
    "    def __init__(self, source_dir, output_dir):\n",
    "        self.source_dir = Path(source_dir)\n",
    "        self.output_dir = Path(output_dir)\n",
    "        \n",
    "        # Genre mapping from filename prefixes\n",
    "        self.genres = {\n",
    "            'DRAM': 'Drama',\n",
    "            'HUMA': 'Humanities', \n",
    "            'LEGA': 'Legal',\n",
    "            'NARR': 'Narrative',\n",
    "            'NEWS': 'Newspapers',\n",
    "            'SCIE': 'Scientific',\n",
    "            'SERM': 'Sermons'\n",
    "        }\n",
    "        \n",
    "        # Time period bins\n",
    "        self.periods = {\n",
    "            'P1': '1650-1700',\n",
    "            'P2': '1700-1750', \n",
    "            'P3': '1750-1800'\n",
    "        }\n",
    "        \n",
    "    def extract_file_info(self, filename):\n",
    "        \"\"\"Extract genre, period, and year from filename\"\"\"\n",
    "        # Pattern: GENRE_PERIOD_REGION_YEAR_TITLE.xml\n",
    "        # Example: DRAM_P1_NoD_1673_Leonilda.xml\n",
    "        \n",
    "        pattern = r'([A-Z]{4})_([P][1-3])_([A-Za-z]+)_(\\d{4})_(.+)\\.xml'\n",
    "        match = re.match(pattern, filename)\n",
    "        \n",
    "        if not match:\n",
    "            return None\n",
    "            \n",
    "        genre_code, period_code, region, year, title = match.groups()\n",
    "        \n",
    "        return {\n",
    "            'genre': self.genres.get(genre_code, 'Unknown'),\n",
    "            'genre_code': genre_code,\n",
    "            'period': self.periods.get(period_code, 'Unknown'),\n",
    "            'period_code': period_code,\n",
    "            'region': region,\n",
    "            'year': int(year),\n",
    "            'title': title,\n",
    "            'filename': filename\n",
    "        }\n",
    "    \n",
    "    def organize_files(self):\n",
    "        \"\"\"Main function to organize all LING-GATE files\"\"\"\n",
    "        \n",
    "        # Create output directory structure\n",
    "        self.create_directory_structure()\n",
    "        \n",
    "        # Stats tracking\n",
    "        stats = defaultdict(lambda: defaultdict(int))\n",
    "        processed_files = []\n",
    "        error_files = []\n",
    "        \n",
    "        # Process each XML file\n",
    "        for xml_file in self.source_dir.glob(\"*.xml\"):\n",
    "            try:\n",
    "                file_info = self.extract_file_info(xml_file.name)\n",
    "                \n",
    "                if file_info:\n",
    "                    # Create destination path\n",
    "                    dest_dir = self.output_dir / file_info['period'] / file_info['genre']\n",
    "                    dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "                    \n",
    "                    # Copy file to organized location\n",
    "                    dest_path = dest_dir / xml_file.name\n",
    "                    shutil.copy2(xml_file, dest_path)\n",
    "                    \n",
    "                    # Update stats\n",
    "                    stats[file_info['period']][file_info['genre']] += 1\n",
    "                    processed_files.append(file_info)\n",
    "                    \n",
    "                    print(f\"✓ {xml_file.name} → {file_info['period']}/{file_info['genre']}\")\n",
    "                    \n",
    "                else:\n",
    "                    error_files.append(xml_file.name)\n",
    "                    print(f\"✗ Could not parse: {xml_file.name}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                error_files.append(xml_file.name)\n",
    "                print(f\"✗ Error processing {xml_file.name}: {e}\")\n",
    "        \n",
    "        # Generate summary report\n",
    "        self.generate_report(stats, processed_files, error_files)\n",
    "        \n",
    "        return stats, processed_files, error_files\n",
    "    \n",
    "    def create_directory_structure(self):\n",
    "        \"\"\"Create organized directory structure\"\"\"\n",
    "        for period in self.periods.values():\n",
    "            for genre in self.genres.values():\n",
    "                dir_path = self.output_dir / period / genre\n",
    "                dir_path.mkdir(parents=True, exist_ok=True)\n",
    "                \n",
    "    def generate_report(self, stats, processed_files, error_files):\n",
    "        \"\"\"Generate organization summary report\"\"\"\n",
    "        \n",
    "        report_path = self.output_dir / \"organization_report.txt\"\n",
    "        \n",
    "        with open(report_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"GerManC Corpus Organization Report\\n\")\n",
    "            f.write(\"=\" * 40 + \"\\n\\n\")\n",
    "            \n",
    "            # Summary statistics\n",
    "            f.write(f\"Total files processed: {len(processed_files)}\\n\")\n",
    "            f.write(f\"Total files with errors: {len(error_files)}\\n\\n\")\n",
    "            \n",
    "            # Files by period and genre\n",
    "            f.write(\"Files by Period and Genre:\\n\")\n",
    "            f.write(\"-\" * 30 + \"\\n\")\n",
    "            \n",
    "            for period in sorted(stats.keys()):\n",
    "                f.write(f\"\\n{period}:\\n\")\n",
    "                for genre in sorted(stats[period].keys()):\n",
    "                    count = stats[period][genre]\n",
    "                    f.write(f\"  {genre}: {count} files\\n\")\n",
    "            \n",
    "            # Year distribution\n",
    "            f.write(\"\\n\\nYear Distribution:\\n\")\n",
    "            f.write(\"-\" * 20 + \"\\n\")\n",
    "            years = [info['year'] for info in processed_files]\n",
    "            if years:\n",
    "                f.write(f\"Earliest: {min(years)}\\n\")\n",
    "                f.write(f\"Latest: {max(years)}\\n\")\n",
    "                f.write(f\"Range: {max(years) - min(years)} years\\n\")\n",
    "            \n",
    "            # Error files\n",
    "            if error_files:\n",
    "                f.write(\"\\n\\nFiles with errors:\\n\")\n",
    "                f.write(\"-\" * 20 + \"\\n\")\n",
    "                for error_file in error_files:\n",
    "                    f.write(f\"  {error_file}\\n\")\n",
    "        \n",
    "        print(f\"\\n📊 Report saved to: {report_path}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Example usage\"\"\"\n",
    "    \n",
    "    # Set your paths here\n",
    "    source_directory = \"/Users/rohan/Downloads/2544/LING-GATE/\"  # Where your XML files are\n",
    "    output_directory = \"/Users/rohan/Downloads/2544/organized_germanc\"                # Where to create organized structure\n",
    "    \n",
    "    # Create organizer and run\n",
    "    organizer = GerManCOrganizer(source_directory, output_directory)\n",
    "    stats, processed, errors = organizer.organize_files()\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n🎉 Organization complete!\")\n",
    "    print(f\"📁 Organized {len(processed)} files\")\n",
    "    print(f\"❌ {len(errors)} errors\")\n",
    "    print(f\"📊 Check organization_report.txt for details\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce2b13a-0b0c-4f60-ac2d-03f0e3d6993d",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18c64419-3ec4-40ad-bdd5-d81699cfc4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Processed: HUMA_P2_NoD_1737_Koenigstein.xml\n",
      "✓ Processed: HUMA_P2_OMD_1725_Hass.xml\n",
      "✓ Processed: HUMA_P2_WOD_1744_Pfaltz.xml\n",
      "✓ Processed: HUMA_P2_OOD_1707_HundertNarren.xml\n",
      "✓ Processed: HUMA_P2_WMD_1737_Curiositaeten.xml\n",
      "✓ Processed: HUMA_P2_OOD_1704_WasserKunst.xml\n",
      "✓ Processed: HUMA_P2_OOD_1731_AntiquitaetenSchatz.xml\n",
      "✓ Processed: HUMA_P2_WMD_1739_Stollberg.xml\n",
      "✓ Processed: HUMA_P2_NoD_1720_Remarques.xml\n",
      "✓ Processed: HUMA_P2_WOD_1740_Poesie.xml\n",
      "✓ Processed: HUMA_P2_WMD_1748_Samuel.xml\n",
      "✓ Processed: HUMA_P2_WOD_1741_Antiquitaeten.xml\n",
      "✓ Processed: HUMA_P2_NoD_1739_MusicalischInterval.xml\n",
      "✓ Processed: HUMA_P2_OMD_1717_DienstMaegde.xml\n",
      "✓ Processed: HUMA_P2_OMD_1729_Biedermann.xml\n",
      "✓ Processed: SERM_P2_OMD_1715_Beerdigung.xml\n",
      "✓ Processed: SERM_P2_WMD_1702_Leben.xml\n",
      "✓ Processed: SERM_P2_WMD_1721_HeilBronnen.xml\n",
      "✓ Processed: SERM_P2_NoD_1715_Klugheit.xml\n",
      "✓ Processed: SERM_P2_WOD_1739_Kranckentrost.xml\n",
      "✓ Processed: SERM_P2_NoD_1730_JubelFeste.xml\n",
      "✓ Processed: SERM_P2_OMD_1734_Evangelisch.xml\n",
      "✓ Processed: SERM_P2_NoD_1715_Seeligkeit.xml\n",
      "✓ Processed: SERM_P2_OOD_1709_Orgel.xml\n",
      "✓ Processed: SERM_P2_WOD_1730_SeelenLiecht.xml\n",
      "✓ Processed: SERM_P2_OOD_1700_FeyerTag.xml\n",
      "✓ Processed: SERM_P2_WOD_1708_Zotten.xml\n",
      "✓ Processed: SERM_P2_WMD_1743_TrostPredigt.xml\n",
      "✓ Processed: SERM_P2_OOD_1728_Verstellte.xml\n",
      "✓ Processed: SERM_P2_OMD_1706_GedaechtnisPredigt.xml\n",
      "✓ Processed: NARR_P2_NoD_1715_Africa.xml\n",
      "✓ Processed: NARR_P2_OMD_1731_Seefahrer.xml\n",
      "✓ Processed: NARR_P2_WMD_1750_Teutsche.xml\n",
      "✓ Processed: NARR_P2_OOD_1734_TaendlMarckt.xml\n",
      "✓ Processed: NARR_P2_WOD_1724_JungferRobinsone.xml\n",
      "✓ Processed: NARR_P2_WMD_1716_Fleurie.xml\n",
      "✓ Processed: NARR_P2_OMD_1738_LebensBeschreibung.xml\n",
      "✓ Processed: NARR_P2_OOD_1703_Narrennest.xml\n",
      "✓ Processed: NARR_P2_WMD_1742_RedlicheMann.xml\n",
      "✓ Processed: NARR_P2_OOD_1715_HeldenGeschichte.xml\n",
      "✓ Processed: NARR_P2_WOD_1744_Fabeln.xml\n",
      "✓ Processed: NARR_P2_NoD_1706_SatyrischerRoman.xml\n",
      "✓ Processed: NARR_P2_NoD_1709_OstIndien.xml\n",
      "✓ Processed: NARR_P2_WOD_1746_Muetze.xml\n",
      "✓ Processed: NARR_P2_OMD_1708_Affecten.xml\n",
      "✓ Processed: NEWS_P2_OOD_1702_muenchen2.xml\n",
      "✓ Processed: NEWS_P2_NoD_1735_berlin.xml\n",
      "✓ Processed: NEWS_P2_OOD_1702_muenchen1.xml\n",
      "✓ Processed: NEWS_P2_WMD_1701_hanau2.xml\n",
      "✓ Processed: NEWS_P2_OMD_1724_halle.xml\n",
      "✓ Processed: NEWS_P2_WMD_1701_hanau1.xml\n",
      "✓ Processed: NEWS_P2_OMD_1722_leipzig2.xml\n",
      "✓ Processed: NEWS_P2_NoD_1740_berlin1.xml\n",
      "✓ Processed: NEWS_P2_WMD_1750_frankfurt.xml\n",
      "✓ Processed: NEWS_P2_NoD_1702_hamburg.xml\n",
      "✓ Processed: NEWS_P2_OMD_1722_leipzig1.xml\n",
      "✓ Processed: NEWS_P2_NoD_1740_berlin2.xml\n",
      "✓ Processed: NEWS_P2_WOD_1722_zuerich.xml\n",
      "✓ Processed: NEWS_P2_OOD_1712_wien.xml\n",
      "✓ Processed: NEWS_P2_OOD_1713_wien.xml\n",
      "✓ Processed: NEWS_P2_OOD_1744_graz.xml\n",
      "✓ Processed: NEWS_P2_OMD_1744_erfurt2.xml\n",
      "✓ Processed: NEWS_P2_WMD_1701_frankfurt.xml\n",
      "✓ Processed: NEWS_P2_WOD_1749_loerrach2.xml\n",
      "✓ Processed: NEWS_P2_WOD_1723_augsburg1.xml\n",
      "✓ Processed: NEWS_P2_OMD_1744_erfurt1.xml\n",
      "✓ Processed: NEWS_P2_WOD_1749_loerrach1.xml\n",
      "✓ Processed: NEWS_P2_WOD_1723_augsburg2.xml\n",
      "✓ Processed: LEGA_P2_WOD_1738_Constantz.xml\n",
      "✓ Processed: LEGA_P2_NoD_1707_Reglement.xml\n",
      "✓ Processed: LEGA_P2_OOD_1704_OrdnungNuernberg.xml\n",
      "✓ Processed: LEGA_P2_OMD_1709_WaeysenOrdnung.xml\n",
      "✓ Processed: LEGA_P2_WOD_1729_WechselRecht.xml\n",
      "✓ Processed: LEGA_P2_NoD_1724_StadtRecht.xml\n",
      "✓ Processed: LEGA_P2_WMD_1724_GesetzBuch.xml\n",
      "✓ Processed: LEGA_P2_OOD_1719_Privilegien.xml\n",
      "✓ Processed: LEGA_P2_WOD_1711_HalsGericht.xml\n",
      "✓ Processed: LEGA_P2_WMD_1733_Heyrathen.xml\n",
      "✓ Processed: LEGA_P2_OMD_1723_JurisMilitaris.xml\n",
      "✓ Processed: LEGA_P2_WMD_1720_VatterMord.xml\n",
      "✓ Processed: LEGA_P2_NoD_1700_Braunschweig.xml\n",
      "✓ Processed: LEGA_P2_OMD_1710_ReichsArchiv.xml\n",
      "✓ Processed: LEGA_P2_OOD_1709_Promptuarii.xml\n",
      "✓ Processed: DRAM_P2_WOD_1748_Hoelle.xml\n",
      "✓ Processed: DRAM_P2_WMD_1745_Zuegellose.xml\n",
      "✓ Processed: DRAM_P2_OOD_1733_Ciro.xml\n",
      "✓ Processed: DRAM_P2_WMD_1742_Bookesbeutel.xml\n",
      "✓ Processed: DRAM_P2_OMD_1736_Fischbein.xml\n",
      "✓ Processed: DRAM_P2_WOD_1702_Helvetia.xml\n",
      "✓ Processed: DRAM_P2_OOD_1725_Venceslao.xml\n",
      "✓ Processed: DRAM_P2_NoD_1707_SchaeferSpiel.xml\n",
      "✓ Processed: DRAM_P2_NoD_1711_Croesus.xml\n",
      "✓ Processed: DRAM_P2_OOD_1749_Schaeferinsel.xml\n",
      "✓ Processed: DRAM_P2_WMD_1743_DieGeistlichen.xml\n",
      "✓ Processed: DRAM_P2_OMD_1732_Cato.xml\n",
      "✓ Processed: DRAM_P2_OMD_1747_Schwestern.xml\n",
      "✓ Processed: DRAM_P2_WOD_1737_Verehrung.xml\n",
      "✓ Processed: DRAM_P2_NoD_1749_AlteJungfer.xml\n",
      "✓ Processed: SCIE_P2_WOD_1741_Erden.xml\n",
      "✓ Processed: SCIE_P2_WMD_1744_SelbstArtzt.xml\n",
      "✓ Processed: SCIE_P2_OMD_1737_Medica.xml\n",
      "✓ Processed: SCIE_P2_WOD_1720_FangSchlaeussen.xml\n",
      "✓ Processed: SCIE_P2_NoD_1734_Barometer.xml\n",
      "✓ Processed: SCIE_P2_NoD_1736_Anweisung.xml\n",
      "✓ Processed: SCIE_P2_OOD_1745_Mathematicus.xml\n",
      "✓ Processed: SCIE_P2_WMD_1714_Kleinod.xml\n",
      "✓ Processed: SCIE_P2_WMD_1702_Armuth.xml\n",
      "✓ Processed: SCIE_P2_OOD_1705_WerckSchul.xml\n",
      "✓ Processed: SCIE_P2_WOD_1708_WunderbarenWelt.xml\n",
      "✓ Processed: SCIE_P2_NoD_1744_Cometen.xml\n",
      "✓ Processed: SCIE_P2_OOD_1722_NordScheines.xml\n",
      "✓ Processed: SCIE_P2_OMD_1717_Materialist.xml\n",
      "✓ Processed: SCIE_P2_OMD_1731_HarnRuhr.xml\n",
      "✓ Processed: HUMA_P3_WMD_1772_Baukunst.xml\n",
      "✓ Processed: HUMA_P3_WOD_1784_Weibs.xml\n",
      "✓ Processed: HUMA_P3_WOD_1795_Dichtung.xml\n",
      "✓ Processed: HUMA_P3_NoD_1762_Kreuzzuege.xml\n",
      "✓ Processed: HUMA_P3_WMD_1789_Italien.xml\n",
      "✓ Processed: HUMA_P3_OOD_1792_Alterthuemer.xml\n",
      "✓ Processed: HUMA_P3_NoD_1772_Ursprung.xml\n",
      "✓ Processed: HUMA_P3_OOD_1774_Emil.xml\n",
      "✓ Processed: HUMA_P3_NoD_1788_Menschen.xml\n",
      "✓ Processed: HUMA_P3_WMD_1777_Homburg.xml\n",
      "✓ Processed: HUMA_P3_OMD_1777_Dichtkunst.xml\n",
      "✓ Processed: HUMA_P3_OMD_1798_Sondershausen.xml\n",
      "✓ Processed: HUMA_P3_WOD_1768_Roemer.xml\n",
      "✓ Processed: HUMA_P3_OOD_1778_Pons.xml\n",
      "✓ Processed: HUMA_P3_OMD_1774_Roman.xml\n",
      "✓ Processed: SERM_P3_OOD_1792_Sonntagen.xml\n",
      "✓ Processed: SERM_P3_OMD_1760_Folgen.xml\n",
      "✓ Processed: SERM_P3_WOD_1792_Hegel.xml\n",
      "✓ Processed: SERM_P3_OOD_1782_Erloeser.xml\n",
      "✓ Processed: SERM_P3_NoD_1798_LetztePredigt.xml\n",
      "✓ Processed: SERM_P3_WOD_1751_DreiKoenig.xml\n",
      "✓ Processed: SERM_P3_OMD_1790_Unruhen.xml\n",
      "✓ Processed: SERM_P3_OMD_1756_Trost.xml\n",
      "✓ Processed: SERM_P3_WOD_1790_Strassburg.xml\n",
      "✓ Processed: SERM_P3_WMD_1774_Gewohnheit.xml\n",
      "✓ Processed: SERM_P3_WMD_1780_LottoSucht.xml\n",
      "✓ Processed: SERM_P3_OOD_1751_Elisabetha.xml\n",
      "✓ Processed: SERM_P3_NoD_1765_Trauerrede.xml\n",
      "✓ Processed: SERM_P3_NoD_1770_Gottesdienst.xml\n",
      "✓ Processed: SERM_P3_WMD_1780_Feuersbrunst.xml\n",
      "✓ Processed: NARR_P3_OOD_1789_PeterProsch.xml\n",
      "✓ Processed: NARR_P3_OOD_1796_Quintus.xml\n",
      "✓ Processed: NARR_P3_WMD_1782_Fragmente.xml\n",
      "✓ Processed: NARR_P3_NoD_1786_Muenchhausen.xml\n",
      "✓ Processed: NARR_P3_WOD_1771_Usong.xml\n",
      "✓ Processed: NARR_P3_WMD_1783_MoralischeErzaehlungen.xml\n",
      "✓ Processed: NARR_P3_WOD_1766_Agathon.xml\n",
      "✓ Processed: NARR_P3_NoD_1796_Siebenkaes.xml\n",
      "✓ Processed: NARR_P3_OMD_1776_Zerbin.xml\n",
      "✓ Processed: NARR_P3_OOD_1787_Aglais.xml\n",
      "✓ Processed: NARR_P3_OMD_1782_Volksmaerchen.xml\n",
      "✓ Processed: NARR_P3_OMD_1774_Werther.xml\n",
      "✓ Processed: NARR_P3_WOD_1797_Hyperion.xml\n",
      "✓ Processed: NARR_P3_NoD_1790_AntonReiser.xml\n",
      "✓ Processed: NARR_P3_WMD_1775_Bacchidon.xml\n",
      "✓ Processed: NEWS_P3_OMD_1769_erfurt.xml\n",
      "✓ Processed: NEWS_P3_WOD_1784_freiburg2.xml\n",
      "✓ Processed: NEWS_P3_WOD_1784_freiburg1.xml\n",
      "✓ Processed: NEWS_P3_NoD_1786_wolfenbuettel1.xml\n",
      "✓ Processed: NEWS_P3_WMD_1784_mannheim.xml\n",
      "✓ Processed: NEWS_P3_WMD_1797_hanau.xml\n",
      "✓ Processed: NEWS_P3_NoD_1786_wolfenbuettel2.xml\n",
      "✓ Processed: NEWS_P3_WOD_1798_tuebingen.xml\n",
      "✓ Processed: NEWS_P3_WMD_1793_mainz.xml\n",
      "✓ Processed: NEWS_P3_OOD_1780_wien.xml\n",
      "✓ Processed: NEWS_P3_WOD_1781_heilbronn.xml\n",
      "✓ Processed: NEWS_P3_OOD_1791_bayreuth.xml\n",
      "✓ Processed: NEWS_P3_OMD_1789_gotha.xml\n",
      "✓ Processed: NEWS_P3_OOD_1790_erlangen.xml\n",
      "✓ Processed: NEWS_P3_OMD_1784_gotha.xml\n",
      "✓ Processed: NEWS_P3_NoD_1796_stettin.xml\n",
      "✓ Processed: NEWS_P3_OMD_1790_gotha.xml\n",
      "✓ Processed: NEWS_P3_NoD_1798_danzig.xml\n",
      "✓ Processed: LEGA_P3_NoD_1751_FeuerOrdnung.xml\n",
      "✓ Processed: LEGA_P3_OOD_1769_Theresiana.xml\n",
      "✓ Processed: LEGA_P3_WMD_1772_RegimentsVerfassung.xml\n",
      "✓ Processed: LEGA_P3_OOD_1750_HofRathsOrdnung.xml\n",
      "✓ Processed: LEGA_P3_NoD_1757_Rostock.xml\n",
      "✓ Processed: LEGA_P3_OMD_1767_ProcessOrdnung.xml\n",
      "✓ Processed: LEGA_P3_OMD_1777_MuehlenOrdnung.xml\n",
      "✓ Processed: LEGA_P3_WMD_1756_StaatsArchiv.xml\n",
      "✓ Processed: LEGA_P3_WOD_1791_Muenze.xml\n",
      "✓ Processed: LEGA_P3_OMD_1784_Erbstatuten.xml\n",
      "✓ Processed: LEGA_P3_NoD_1796_Landtage.xml\n",
      "✓ Processed: LEGA_P3_OOD_1752_Gerichtbarkeit.xml\n",
      "✓ Processed: LEGA_P3_WOD_1769_ZunftOrdnungen.xml\n",
      "✓ Processed: LEGA_P3_WMD_1792_Reichshofrath.xml\n",
      "✓ Processed: LEGA_P3_WOD_1787_Cameralrecht.xml\n",
      "✓ Processed: DRAM_P3_NoD_1764_Salomo.xml\n",
      "✓ Processed: DRAM_P3_OOD_1764_Maegera.xml\n",
      "✓ Processed: DRAM_P3_NoD_1767_Minna.xml\n",
      "✓ Processed: DRAM_P3_WMD_1787_Verbrechen.xml\n",
      "✓ Processed: DRAM_P3_OMD_1788_Egmont.xml\n",
      "✓ Processed: DRAM_P3_OMD_1775_LeidendeWeib.xml\n",
      "✓ Processed: DRAM_P3_WOD_1762_Evander.xml\n",
      "✓ Processed: DRAM_P3_OMD_1774_Hofmeister.xml\n",
      "✓ Processed: DRAM_P3_NoD_1776_Zwillinge.xml\n",
      "✓ Processed: DRAM_P3_OOD_1798_Donauweibchen.xml\n",
      "✓ Processed: DRAM_P3_WMD_1780_Hausvater.xml\n",
      "✓ Processed: DRAM_P3_WMD_1773_Goetz.xml\n",
      "✓ Processed: DRAM_P3_WOD_1781_Raeuber.xml\n",
      "✓ Processed: DRAM_P3_OOD_1782_Serail.xml\n",
      "✓ Processed: DRAM_P3_WOD_1783_Elfride.xml\n",
      "✓ Processed: SCIE_P3_NoD_1799_Gasarten.xml\n",
      "✓ Processed: SCIE_P3_WOD_1774_Hygrometrie.xml\n",
      "✓ Processed: SCIE_P3_WOD_1787_Botanik.xml\n",
      "✓ Processed: SCIE_P3_WMD_1777_Logik.xml\n",
      "✓ Processed: SCIE_P3_OOD_1786_Polizey.xml\n",
      "✓ Processed: SCIE_P3_WMD_1781_Forstwissenschaft.xml\n",
      "✓ Processed: SCIE_P3_WOD_1780_Instrument.xml\n",
      "✓ Processed: SCIE_P3_NoD_1775_Chemie.xml\n",
      "✓ Processed: SCIE_P3_OMD_1781_Chymie.xml\n",
      "✓ Processed: SCIE_P3_OOD_1780_ZeichenInstruments.xml\n",
      "✓ Processed: SCIE_P3_OMD_1781_Akademie.xml\n",
      "✓ Processed: SCIE_P3_OMD_1778_MineralogischeGeographie.xml\n",
      "✓ Processed: SCIE_P3_OOD_1788_Chimie.xml\n",
      "✓ Processed: SCIE_P3_NoD_1761_Menschlich.xml\n",
      "✓ Processed: SCIE_P3_WMD_1753_ProbierSteins.xml\n",
      "✓ Processed: HUMA_P1_NoD_1667_Ratseburg.xml\n",
      "✓ Processed: HUMA_P1_WMD_1692_Christus.xml\n",
      "✓ Processed: HUMA_P1_OOD_1680_MercksWienn.xml\n",
      "✓ Processed: HUMA_P1_NoD_1663_HaubtSprache.xml\n",
      "✓ Processed: HUMA_P1_OMD_1654_Rosetum.xml\n",
      "✓ Processed: HUMA_P1_OMD_1685_ChristenStat.xml\n",
      "✓ Processed: HUMA_P1_WMD_1699_KetzerHistorie.xml\n",
      "✓ Processed: HUMA_P1_WOD_1698_Mythoscopia.xml\n",
      "✓ Processed: HUMA_P1_OOD_1689_Crain.xml\n",
      "✓ Processed: HUMA_P1_WOD_1686_Betrachtung.xml\n",
      "✓ Processed: HUMA_P1_OOD_1690_Proteus.xml\n",
      "✓ Processed: HUMA_P1_WOD_1662_Musurgia.xml\n",
      "✓ Processed: HUMA_P1_WMD_1674_BilderSchatz.xml\n",
      "✓ Processed: HUMA_P1_NoD_1674_NaturalienKammer.xml\n",
      "✓ Processed: HUMA_P1_OMD_1680_Bericht.xml\n",
      "✓ Processed: SERM_P1_WOD_1660_LeichPredigt.xml\n",
      "✓ Processed: SERM_P1_OMD_1680_Balcken.xml\n",
      "✓ Processed: SERM_P1_WMD_1674_Trost.xml\n",
      "✓ Processed: SERM_P1_WOD_1683_TrostPredigt.xml\n",
      "✓ Processed: SERM_P1_OOD_1663_Amaradvlcis.xml\n",
      "✓ Processed: SERM_P1_OMD_1680_SursumDeosum.xml\n",
      "✓ Processed: SERM_P1_NoD_1677_LeichSermon.xml\n",
      "✓ Processed: SERM_P1_OMD_1672_Advent.xml\n",
      "✓ Processed: SERM_P1_WMD_1699_Solms.xml\n",
      "✓ Processed: SERM_P1_NoD_1666_Erbteil.xml\n",
      "✓ Processed: SERM_P1_WOD_1654_Eytelkeit.xml\n",
      "✓ Processed: SERM_P1_OOD_1686_KlagseufftzendesAch.xml\n",
      "✓ Processed: SERM_P1_NoD_1690_WilleGottes.xml\n",
      "✓ Processed: SERM_P1_WMD_1662_Funeralia.xml\n",
      "✓ Processed: SERM_P1_OOD_1660_EinweihungsPredigt.xml\n",
      "✓ Processed: NARR_P1_OMD_1671_Ruebezahl.xml\n",
      "✓ Processed: NARR_P1_NoD_1659_Herkules.xml\n",
      "✓ Processed: NARR_P1_WOD_1689_Miranten.xml\n",
      "✓ Processed: NARR_P1_WMD_1664_Levante.xml\n",
      "✓ Processed: NARR_P1_NoD_1658_Morgenlaendisch.xml\n",
      "✓ Processed: NARR_P1_WOD_1672_Melcher.xml\n",
      "✓ Processed: NARR_P1_WMD_1696_Schelmuffsky.xml\n",
      "✓ Processed: NARR_P1_OMD_1689_Arminius.xml\n",
      "✓ Processed: NARR_P1_OOD_1669_Aramena.xml\n",
      "✓ Processed: NARR_P1_OOD_1667_Simplicissimus.xml\n",
      "✓ Processed: NARR_P1_WMD_1696_DerEdelmann.xml\n",
      "✓ Processed: NARR_P1_NoD_1682_Mandorell.xml\n",
      "✓ Processed: NARR_P1_WOD_1682_Feuermaeuer.xml\n",
      "✓ Processed: NARR_P1_OMD_1700_Banise.xml\n",
      "✓ Processed: NARR_P1_OOD_1682_Winternaechte.xml\n",
      "✓ Processed: NEWS_P1_OOD_1684_muenchmerc.xml\n",
      "✓ Processed: NEWS_P1_OMD_1666_leipzig2.xml\n",
      "✓ Processed: NEWS_P1_OMD_1666_leipzig1.xml\n",
      "✓ Processed: NEWS_P1_WOD_1662_strassburg1.xml\n",
      "✓ Processed: NEWS_P1_WOD_1685_lindau.xml\n",
      "✓ Processed: NEWS_P1_WOD_1662_strassburg2.xml\n",
      "✓ Processed: NEWS_P1_NoD_1698_altona.xml\n",
      "✓ Processed: NEWS_P1_OMD_1683_breslau.xml\n",
      "✓ Processed: NEWS_P1_OOD_1679_nuernberg1.xml\n",
      "✓ Processed: NEWS_P1_OMD_1684_breslau.xml\n",
      "✓ Processed: NEWS_P1_OOD_1679_nuernberg2.xml\n",
      "✓ Processed: NEWS_P1_OOD_1659_muenchen2.xml\n",
      "✓ Processed: NEWS_P1_OOD_1659_muenchmerc.xml\n",
      "✓ Processed: NEWS_P1_WMD_1662_koeln.xml\n",
      "✓ Processed: NEWS_P1_WOD_1681_zuerich.xml\n",
      "✓ Processed: NEWS_P1_OOD_1659_muenchen1.xml\n",
      "✓ Processed: NEWS_P1_NoD_1666_berlin2.xml\n",
      "✓ Processed: NEWS_P1_WMD_1671_frankfurt1.xml\n",
      "✓ Processed: NEWS_P1_NoD_1666_berlin1.xml\n",
      "✓ Processed: NEWS_P1_WMD_1699_koeln.xml\n",
      "✓ Processed: NEWS_P1_NoD_1673_hamburg.xml\n",
      "✓ Processed: NEWS_P1_WMD_1671_frankfurt2.xml\n",
      "✓ Processed: NEWS_P1_WOD_1689_lindau.xml\n",
      "✓ Processed: NEWS_P1_OMD_1687_leipzig.xml\n",
      "✓ Processed: NEWS_P1_WMD_1663_koeln.xml\n",
      "✓ Processed: LEGA_P1_WOD_1654_HoffgerichtsOrdnung.xml\n",
      "✓ Processed: LEGA_P1_WOD_1698_LandsOrdnung.xml\n",
      "✓ Processed: LEGA_P1_WOD_1683_Ulm.xml\n",
      "✓ Processed: LEGA_P1_OOD_1659_SchulOrdnung.xml\n",
      "✓ Processed: LEGA_P1_OOD_1657_Wildtfang.xml\n",
      "✓ Processed: LEGA_P1_NoD_1657_Luebeck.xml\n",
      "✓ Processed: LEGA_P1_NoD_1673_BergOrdnung.xml\n",
      "✓ Processed: LEGA_P1_WMD_1698_BergkRecht.xml\n",
      "✓ Processed: LEGA_P1_OOD_1700_GesetzNuernberg.xml\n",
      "✓ Processed: LEGA_P1_OMD_1680_Dreszden.xml\n",
      "✓ Processed: LEGA_P1_WMD_1700_LandRecht.xml\n",
      "✓ Processed: LEGA_P1_WMD_1694_RathsSatzung.xml\n",
      "✓ Processed: LEGA_P1_NoD_1695_Duesseldorff.xml\n",
      "✓ Processed: LEGA_P1_OMD_1659_Hexen.xml\n",
      "✓ Processed: LEGA_P1_OMD_1674_BergOrdnung.xml\n",
      "✓ Processed: DRAM_P1_OOD_1675_Pirrus.xml\n",
      "✓ Processed: DRAM_P1_OMD_1657_Cardenio.xml\n",
      "✓ Processed: DRAM_P1_WOD_1687_Joseph.xml\n",
      "✓ Processed: DRAM_P1_WOD_1663_Carle.xml\n",
      "✓ Processed: DRAM_P1_NoD_1673_Leonilda.xml\n",
      "✓ Processed: DRAM_P1_WMD_1670_Comoedianten.xml\n",
      "✓ Processed: DRAM_P1_NoD_1700_Freyheit.xml\n",
      "✓ Processed: DRAM_P1_OMD_1661_Cleopatra.xml\n",
      "✓ Processed: DRAM_P1_WMD_1662_Tomyris.xml\n",
      "✓ Processed: DRAM_P1_OOD_1682_Abraham.xml\n",
      "✓ Processed: DRAM_P1_OMD_1683_Masaniello.xml\n",
      "✓ Processed: DRAM_P1_WMD_1668_ChristRuehmendes.xml\n",
      "✓ Processed: DRAM_P1_OOD_1682_LiebesSig.xml\n",
      "✓ Processed: DRAM_P1_WOD_1699_LiebesStreit.xml\n",
      "✓ Processed: DRAM_P1_NoD_1699_Euridice.xml\n",
      "✓ Processed: SCIE_P1_OOD_1681_CometenGespoetts.xml\n",
      "✓ Processed: SCIE_P1_NoD_1680_ConsiliumMedicum.xml\n",
      "✓ Processed: SCIE_P1_WMD_1676_ArtzneyBuch.xml\n",
      "✓ Processed: SCIE_P1_OOD_1689_PferdKunst.xml\n",
      "✓ Processed: SCIE_P1_OMD_1700_BergBau.xml\n",
      "✓ Processed: SCIE_P1_OMD_1664_StraussStern.xml\n",
      "✓ Processed: SCIE_P1_WOD_1693_Kranckheit.xml\n",
      "✓ Processed: SCIE_P1_WMD_1687_ArtzneyKunst.xml\n",
      "✓ Processed: SCIE_P1_WOD_1663_KunstSpiegel.xml\n",
      "✓ Processed: SCIE_P1_OMD_1672_Handwercke.xml\n",
      "✓ Processed: SCIE_P1_WMD_1680_Epidemica.xml\n",
      "✓ Processed: SCIE_P1_WOD_1665_Cometen.xml\n",
      "✓ Processed: SCIE_P1_NoD_1684_Durchfall.xml\n",
      "✓ Processed: SCIE_P1_NoD_1672_Prognosticis.xml\n",
      "✓ Processed: SCIE_P1_OOD_1665_Feldmessen.xml\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 288\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReady for Phase 3: Database creation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 288\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[3], line 282\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    279\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/rohan/Downloads/2544/processed_germanc\u001b[39m\u001b[38;5;124m\"\u001b[39m     \u001b[38;5;66;03m# Phase 2 output\u001b[39;00m\n\u001b[1;32m    281\u001b[0m preprocessor \u001b[38;5;241m=\u001b[39m GerManCPreprocessor(organized_dir, output_dir)\n\u001b[0;32m--> 282\u001b[0m stats \u001b[38;5;241m=\u001b[39m preprocessor\u001b[38;5;241m.\u001b[39mprocess_all_files()\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m📊 Preprocessing complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReady for Phase 3: Database creation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 53\u001b[0m, in \u001b[0;36mGerManCPreprocessor.process_all_files\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m                         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✗ Error processing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mxml_file\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Save processed data\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_processed_data()\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m🎉 Processing complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m📄 Documents: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 217\u001b[0m, in \u001b[0;36mGerManCPreprocessor.save_processed_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdocuments:\n\u001b[1;32m    216\u001b[0m     doc_copy \u001b[38;5;241m=\u001b[39m doc\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m--> 217\u001b[0m     doc_copy[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munique_words\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(doc_copy[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munique_words\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    218\u001b[0m     docs_for_json\u001b[38;5;241m.\u001b[39mappend(doc_copy)\n\u001b[1;32m    219\u001b[0m json\u001b[38;5;241m.\u001b[39mdump(docs_for_json, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "GerManC LING-GATE XML Preprocessor - Phase 2: PREPARE\n",
    "Extracts linguistic features from LING-GATE XML files and prepares data for RAG system.\n",
    "\"\"\"\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "class GerManCPreprocessor:\n",
    "    def __init__(self, organized_dir, output_dir):\n",
    "        self.organized_dir = Path(organized_dir)\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Initialize data containers\n",
    "        self.documents = []\n",
    "        self.tokens = []\n",
    "        self.linguistic_features = defaultdict(list)\n",
    "        \n",
    "    def process_all_files(self):\n",
    "        \"\"\"Process all organized XML files\"\"\"\n",
    "        stats = defaultdict(int)\n",
    "        \n",
    "        # Process each period\n",
    "        for period_dir in self.organized_dir.iterdir():\n",
    "            if period_dir.is_dir():\n",
    "                period = period_dir.name\n",
    "                \n",
    "                # Process each genre\n",
    "                for genre_dir in period_dir.iterdir():\n",
    "                    if genre_dir.is_dir():\n",
    "                        genre = genre_dir.name\n",
    "                        \n",
    "                        # Process XML files\n",
    "                        for xml_file in genre_dir.glob(\"*.xml\"):\n",
    "                            try:\n",
    "                                doc_data = self.process_xml_file(xml_file, period, genre)\n",
    "                                if doc_data:\n",
    "                                    self.documents.append(doc_data)\n",
    "                                    stats['processed'] += 1\n",
    "                                    print(f\"✓ Processed: {xml_file.name}\")\n",
    "                                    \n",
    "                            except Exception as e:\n",
    "                                stats['errors'] += 1\n",
    "                                print(f\"✗ Error processing {xml_file.name}: {e}\")\n",
    "        \n",
    "        # Save processed data\n",
    "        self.save_processed_data()\n",
    "        \n",
    "        print(f\"\\n🎉 Processing complete!\")\n",
    "        print(f\"📄 Documents: {stats['processed']}\")\n",
    "        print(f\"🔤 Tokens: {len(self.tokens)}\")\n",
    "        print(f\"❌ Errors: {stats['errors']}\")\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def process_xml_file(self, xml_path, period, genre):\n",
    "        \"\"\"Process single LING-GATE XML file\"\"\"\n",
    "        try:\n",
    "            tree = ET.parse(xml_path)\n",
    "            root = tree.getroot()\n",
    "            \n",
    "            # Extract document metadata\n",
    "            doc_id = xml_path.stem\n",
    "            doc_data = {\n",
    "                'doc_id': doc_id,\n",
    "                'period': period,\n",
    "                'genre': genre,\n",
    "                'filename': xml_path.name,\n",
    "                'year': self.extract_year(xml_path.name),\n",
    "                'region': self.extract_region(xml_path.name),\n",
    "                'sentences': [],\n",
    "                'token_count': 0,\n",
    "                'unique_words': set()\n",
    "            }\n",
    "            \n",
    "            # Process sentences and tokens\n",
    "            sentence_id = 0\n",
    "            \n",
    "            # Find all sentence-like structures\n",
    "            for sentence_elem in root.iter():\n",
    "                if self.is_sentence_element(sentence_elem):\n",
    "                    sentence_data = self.process_sentence(\n",
    "                        sentence_elem, doc_id, sentence_id, period, genre\n",
    "                    )\n",
    "                    if sentence_data['tokens']:\n",
    "                        doc_data['sentences'].append(sentence_data)\n",
    "                        sentence_id += 1\n",
    "            \n",
    "            # Update document stats\n",
    "            doc_data['sentence_count'] = len(doc_data['sentences'])\n",
    "            doc_data['unique_words'] = len(doc_data['unique_words'])\n",
    "            \n",
    "            return doc_data\n",
    "            \n",
    "        except ET.ParseError as e:\n",
    "            print(f\"XML Parse Error in {xml_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def process_sentence(self, sentence_elem, doc_id, sent_id, period, genre):\n",
    "        \"\"\"Process sentence and extract tokens\"\"\"\n",
    "        sentence_data = {\n",
    "            'doc_id': doc_id,\n",
    "            'sentence_id': sent_id,\n",
    "            'text': '',\n",
    "            'tokens': []\n",
    "        }\n",
    "        \n",
    "        token_id = 0\n",
    "        \n",
    "        # Extract tokens from sentence\n",
    "        for token_elem in sentence_elem.iter():\n",
    "            if self.is_token_element(token_elem):\n",
    "                token_data = self.extract_token_features(\n",
    "                    token_elem, doc_id, sent_id, token_id, period, genre\n",
    "                )\n",
    "                if token_data:\n",
    "                    sentence_data['tokens'].append(token_data)\n",
    "                    self.tokens.append(token_data)\n",
    "                    token_id += 1\n",
    "        \n",
    "        # Build sentence text\n",
    "        sentence_data['text'] = ' '.join([t['original'] for t in sentence_data['tokens']])\n",
    "        \n",
    "        return sentence_data\n",
    "    \n",
    "    def extract_token_features(self, token_elem, doc_id, sent_id, token_id, period, genre):\n",
    "        \"\"\"Extract linguistic features from token element\"\"\"\n",
    "        \n",
    "        # Get token attributes\n",
    "        original = token_elem.get('norm', token_elem.text or '')\n",
    "        modern = token_elem.get('lemma', original)\n",
    "        pos = token_elem.get('pos', '')\n",
    "        morph = token_elem.get('morph', '')\n",
    "        \n",
    "        # Skip empty tokens\n",
    "        if not original.strip():\n",
    "            return None\n",
    "        \n",
    "        token_data = {\n",
    "            'doc_id': doc_id,\n",
    "            'sentence_id': sent_id,\n",
    "            'token_id': token_id,\n",
    "            'period': period,\n",
    "            'genre': genre,\n",
    "            'original': original.strip(),\n",
    "            'normalized': modern.strip(),\n",
    "            'pos': pos,\n",
    "            'morphology': morph,\n",
    "            'is_spelling_variant': original.lower() != modern.lower(),\n",
    "            'word_length': len(original),\n",
    "            'has_archaic_spelling': self.is_archaic_spelling(original)\n",
    "        }\n",
    "        \n",
    "        # Track linguistic changes\n",
    "        if token_data['is_spelling_variant']:\n",
    "            self.linguistic_features['spelling_variants'].append({\n",
    "                'original': original,\n",
    "                'modern': modern,\n",
    "                'period': period,\n",
    "                'genre': genre,\n",
    "                'pos': pos\n",
    "            })\n",
    "        \n",
    "        return token_data\n",
    "    \n",
    "    def is_sentence_element(self, elem):\n",
    "        \"\"\"Check if element represents a sentence\"\"\"\n",
    "        # Common sentence tags in LING-GATE\n",
    "        sentence_tags = ['s', 'sentence', 'seg']\n",
    "        return elem.tag.lower() in sentence_tags\n",
    "    \n",
    "    def is_token_element(self, elem):\n",
    "        \"\"\"Check if element represents a token/word\"\"\"\n",
    "        # Common token tags in LING-GATE\n",
    "        token_tags = ['w', 'word', 'token', 'pc']  # pc for punctuation\n",
    "        return elem.tag.lower() in token_tags\n",
    "    \n",
    "    def is_archaic_spelling(self, word):\n",
    "        \"\"\"Identify archaic spelling patterns\"\"\"\n",
    "        archaic_patterns = [\n",
    "            r'.*th.*',  # thun, rath\n",
    "            r'.*umb$',  # vmb -> um\n",
    "            r'.*ey.*',  # archaic diphthongs\n",
    "            r'.*ck$',   # certain archaic endings\n",
    "            r'^v[aeiou]', # v- beginnings (vmb)\n",
    "        ]\n",
    "        \n",
    "        word_lower = word.lower()\n",
    "        return any(re.match(pattern, word_lower) for pattern in archaic_patterns)\n",
    "    \n",
    "    def extract_year(self, filename):\n",
    "        \"\"\"Extract year from filename\"\"\"\n",
    "        match = re.search(r'_(\\d{4})_', filename)\n",
    "        return int(match.group(1)) if match else None\n",
    "    \n",
    "    def extract_region(self, filename):\n",
    "        \"\"\"Extract region code from filename\"\"\"\n",
    "        match = re.search(r'_([A-Za-z]+)_\\d{4}_', filename)\n",
    "        return match.group(1) if match else None\n",
    "    \n",
    "    def save_processed_data(self):\n",
    "        \"\"\"Save all processed data in multiple formats\"\"\"\n",
    "        \n",
    "        # 1. Save documents metadata as JSON\n",
    "        docs_file = self.output_dir / \"documents.json\"\n",
    "        with open(docs_file, 'w', encoding='utf-8') as f:\n",
    "            # Convert sets to lists for JSON serialization\n",
    "            docs_for_json = []\n",
    "            for doc in self.documents:\n",
    "                doc_copy = doc.copy()\n",
    "                doc_copy['unique_words'] = list(doc_copy['unique_words'])\n",
    "                docs_for_json.append(doc_copy)\n",
    "            json.dump(docs_for_json, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        # 2. Save tokens as CSV for analysis\n",
    "        tokens_df = pd.DataFrame(self.tokens)\n",
    "        tokens_file = self.output_dir / \"tokens.csv\"\n",
    "        tokens_df.to_csv(tokens_file, index=False, encoding='utf-8')\n",
    "        \n",
    "        # 3. Save linguistic features\n",
    "        features_file = self.output_dir / \"linguistic_features.json\"\n",
    "        with open(features_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(dict(self.linguistic_features), f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        # 4. Save summary statistics\n",
    "        self.save_statistics()\n",
    "        \n",
    "        print(f\"📁 Saved to {self.output_dir}/\")\n",
    "        print(f\"   - documents.json ({len(self.documents)} docs)\")\n",
    "        print(f\"   - tokens.csv ({len(self.tokens)} tokens)\")\n",
    "        print(f\"   - linguistic_features.json\")\n",
    "        print(f\"   - statistics.json\")\n",
    "    \n",
    "    def save_statistics(self):\n",
    "        \"\"\"Generate and save corpus statistics\"\"\"\n",
    "        \n",
    "        # Period distribution\n",
    "        period_stats = defaultdict(int)\n",
    "        for doc in self.documents:\n",
    "            period_stats[doc['period']] += 1\n",
    "        \n",
    "        # Genre distribution\n",
    "        genre_stats = defaultdict(int)\n",
    "        for doc in self.documents:\n",
    "            genre_stats[doc['genre']] += 1\n",
    "        \n",
    "        # Spelling variants by period\n",
    "        variants_by_period = defaultdict(int)\n",
    "        for variant in self.linguistic_features['spelling_variants']:\n",
    "            variants_by_period[variant['period']] += 1\n",
    "        \n",
    "        # Token statistics\n",
    "        token_df = pd.DataFrame(self.tokens)\n",
    "        \n",
    "        stats = {\n",
    "            'total_documents': len(self.documents),\n",
    "            'total_tokens': len(self.tokens),\n",
    "            'period_distribution': dict(period_stats),\n",
    "            'genre_distribution': dict(genre_stats),\n",
    "            'spelling_variants_by_period': dict(variants_by_period),\n",
    "            'average_tokens_per_doc': len(self.tokens) / len(self.documents) if self.documents else 0,\n",
    "            'unique_pos_tags': token_df['pos'].nunique() if not token_df.empty else 0,\n",
    "            'spelling_variant_rate': len(self.linguistic_features['spelling_variants']) / len(self.tokens) if self.tokens else 0\n",
    "        }\n",
    "        \n",
    "        stats_file = self.output_dir / \"statistics.json\"\n",
    "        with open(stats_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(stats, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run preprocessing\"\"\"\n",
    "    organized_dir = \"/Users/rohan/Downloads/2544/organized_germanc\"  # From Phase 1\n",
    "    output_dir = \"/Users/rohan/Downloads/2544/processed_germanc\"     # Phase 2 output\n",
    "    \n",
    "    preprocessor = GerManCPreprocessor(organized_dir, output_dir)\n",
    "    stats = preprocessor.process_all_files()\n",
    "    \n",
    "    print(f\"\\n📊 Preprocessing complete!\")\n",
    "    print(f\"Ready for Phase 3: Database creation\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f27a71-bedc-445e-909a-8179e2d39596",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

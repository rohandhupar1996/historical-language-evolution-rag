# ==========================================
# FILE: src/streamlit_app/streamlit_app.py (Updated)
# ==========================================
"""
Updated Streamlit app that connects to background RAG service
instead of loading models directly.
"""

import streamlit as st
import pandas as pd
import psycopg2
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np
from pathlib import Path
from typing import List, Dict, Any, Optional
import re
import sys
from collections import defaultdict

# Add src to path for imports
current_dir = Path(__file__).parent
src_dir = current_dir.parent
sys.path.insert(0, str(src_dir))

# Import the new RAG client instead of direct RAG imports
from rag_service.rag_client import StreamlitRAGManager

# Page configuration
st.set_page_config(
    page_title="üèõÔ∏è German Historical Corpus Analytics + AI",
    page_icon="üèõÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Enhanced CSS (keeping all original styling + adding RAG service status)
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
        padding: 2rem;
        border-radius: 15px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 8px 32px rgba(30, 60, 114, 0.3);
    }
    
    .rag-status-ready {
        background: linear-gradient(135deg, #00b894 0%, #00a085 100%);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        margin: 1rem 0;
        text-align: center;
        box-shadow: 0 4px 16px rgba(0, 184, 148, 0.3);
    }
    
    .rag-status-error {
        background: linear-gradient(135deg, #e74c3c 0%, #c0392b 100%);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        margin: 1rem 0;
        text-align: center;
        box-shadow: 0 4px 16px rgba(231, 76, 60, 0.3);
    }
    
    .rag-status-warning {
        background: linear-gradient(135deg, #f39c12 0%, #e67e22 100%);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        margin: 1rem 0;
        text-align: center;
        box-shadow: 0 4px 16px rgba(243, 156, 18, 0.3);
    }
    
    .service-info {
        background: #f8f9ff;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #2a5298;
        margin: 1rem 0;
    }
    
    .semantic-result {
        background: linear-gradient(135deg, #a8e6cf 0%, #88d8a3 100%);
        padding: 1rem;
        border-radius: 8px;
        margin: 0.5rem 0;
        border-left: 4px solid #00b894;
    }
    
    /* Keep all other existing styles... */
    .analytics-card {
        background: linear-gradient(135deg, #f8f9ff 0%, #e8f0ff 100%);
        padding: 1.5rem;
        border-radius: 12px;
        border-left: 5px solid #2a5298;
        margin-bottom: 1rem;
        box-shadow: 0 4px 16px rgba(0,0,0,0.1);
    }
    
    .result-card {
        background: #f8f9ff;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #2a5298;
        margin-bottom: 1rem;
    }
    
    .stat-card {
        background: linear-gradient(135deg, #2a5298 0%, #1e3c72 100%);
        padding: 1.5rem;
        border-radius: 12px;
        color: white;
        text-align: center;
        box-shadow: 0 6px 20px rgba(42, 82, 152, 0.3);
    }
</style>
""", unsafe_allow_html=True)

# Database configuration (unchanged)
DB_CONFIG = {
    'host': 'localhost',
    'port': 5432,
    'database': 'germanc_corpus',
    'user': 'rohan',
    'password': '1996'
}

def get_database_connection():
    """Get database connection."""
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        return conn
    except Exception as e:
        st.error(f"Database connection failed: {e}")
        return None

# ==============================================
# UPDATED RAG SYSTEM INTEGRATION (NEW)
# ==============================================

@st.cache_resource
def get_rag_manager():
    """Get cached RAG manager instance that connects to background service."""
    return StreamlitRAGManager()

def render_rag_status():
    """Render RAG service status at the top of the app."""
    rag_manager = get_rag_manager()
    is_available = rag_manager.initialize_rag()
    
    if is_available:
        st.markdown("""
        <div class="rag-status-ready">
            ü§ñ <strong>AI Semantic Search:</strong> Online and Ready
            <br><small>Background RAG service running on port 8001</small>
        </div>
        """, unsafe_allow_html=True)
        return True
    else:
        error = rag_manager.initialization_error or "Unknown error"
        
        if "Cannot connect" in error:
            st.markdown("""
            <div class="rag-status-warning">
                ‚ö†Ô∏è <strong>AI Semantic Search:</strong> Service Not Running
                <br><small>Start background service: <code>./start_rag_service.sh</code></small>
            </div>
            """, unsafe_allow_html=True)
            
            with st.expander("üõ†Ô∏è How to Start AI Service"):
                st.markdown("""
                **To enable AI-powered semantic search:**
                
                1. **Open a new terminal** and navigate to your project directory
                2. **Run the RAG service:** `./start_rag_service.sh` (or `python -m src.rag_service.rag_server`)
                3. **Wait for initialization** (models need to load)
                4. **Refresh this page** - AI features will become available
                
                **Alternative: Start complete system**
                ```bash
                ./start_full_system.sh
                ```
                This starts both RAG service and Streamlit together.
                """)
        else:
            st.markdown(f"""
            <div class="rag-status-error">
                ‚ùå <strong>AI Semantic Search:</strong> Service Error
                <br><small>{error}</small>
            </div>
            """, unsafe_allow_html=True)
        
        return False

# ==============================================
# ALL ORIGINAL SQL ANALYTICS FUNCTIONS (PRESERVED - UNCHANGED)
# ==============================================

def word_frequency_over_time(word):
    """Track word usage changes over time periods."""
    conn = get_database_connection()
    if not conn:
        return None
    
    try:
        query = """
        SELECT 
            period, 
            COUNT(*) as frequency,
            COUNT(*) * 100.0 / SUM(COUNT(*)) OVER() as percentage,
            STRING_AGG(DISTINCT genre, ', ') as genres_found
        FROM chunks 
        WHERE normalized_text ILIKE %s
        GROUP BY period 
        ORDER BY period
        """
        df = pd.read_sql(query, conn, params=[f'%{word}%'])
        return df
    except Exception as e:
        st.error(f"Error in word frequency analysis: {e}")
        return None
    finally:
        conn.close()

def get_corpus_statistics():
    """Get corpus statistics."""
    conn = get_database_connection()
    if not conn:
        return None
    
    try:
        query = """
        SELECT 
            COUNT(*) as total_chunks,
            COUNT(DISTINCT period) as periods,
            COUNT(DISTINCT genre) as genres,
            MIN(year) as earliest_year,
            MAX(year) as latest_year,
            AVG(token_count) as avg_tokens,
            SUM(token_count) as total_tokens
        FROM chunks
        """
        df = pd.read_sql(query, conn)
        return df.iloc[0].to_dict()
    except Exception as e:
        st.error(f"Error fetching statistics: {e}")
        return None
    finally:
        conn.close()

def search_database(query: str, period_filter: str = None, genre_filter: str = None, limit: int = 10):
    """Search the database using PostgreSQL text search."""
    conn = get_database_connection()
    if not conn:
        return [], []
    
    try:
        search_terms = query.split()
        where_conditions = []
        params = []
        
        for i, term in enumerate(search_terms):
            where_conditions.append(f"normalized_text ILIKE %s")
            params.append(f"%{term}%")
        
        search_condition = " AND ".join(where_conditions)
        
        if period_filter and period_filter != "All Periods":
            search_condition += " AND period = %s"
            params.append(period_filter)
        
        if genre_filter and genre_filter != "All Genres":
            search_condition += " AND genre = %s"
            params.append(genre_filter)
        
        search_query = f"""
        SELECT 
            chunk_id,
            normalized_text,
            original_text,
            period,
            genre,
            year,
            filename,
            token_count,
            doc_id
        FROM chunks
        WHERE {search_condition}
        ORDER BY period, year, chunk_id
        LIMIT %s
        """
        
        params.append(limit)
        df = pd.read_sql(search_query, conn, params=params)
        
        return df.to_dict('records'), search_terms
    except Exception as e:
        st.error(f"Search error: {e}")
        return [], []
    finally:
        conn.close()

def get_available_periods():
    """Get available periods from database."""
    conn = get_database_connection()
    if not conn:
        return ["All Periods"]
    
    try:
        query = "SELECT DISTINCT period FROM chunks ORDER BY period"
        df = pd.read_sql(query, conn)
        periods = ["All Periods"] + df['period'].tolist()
        return periods
    except Exception:
        return ["All Periods"]
    finally:
        conn.close()

def get_available_genres():
    """Get available genres from database."""
    conn = get_database_connection()
    if not conn:
        return ["All Genres"]
    
    try:
        query = "SELECT DISTINCT genre FROM chunks ORDER BY genre"
        df = pd.read_sql(query, conn)
        genres = ["All Genres"] + df['genre'].tolist()
        return genres
    except Exception:
        return ["All Genres"]
    finally:
        conn.close()

def highlight_search_terms(text: str, search_terms: List[str]) -> str:
    """Highlight search terms in text."""
    highlighted_text = text
    for term in search_terms:
        if term.strip():
            pattern = re.compile(re.escape(term), re.IGNORECASE)
            highlighted_text = pattern.sub(
                f'<span class="search-highlight">{term}</span>', 
                highlighted_text
            )
    return highlighted_text

# ==============================================
# RENDERING FUNCTIONS (PRESERVED + ENHANCED)
# ==============================================

def render_search_results(results: List[Dict], search_terms: List[str], query: str):
    """Render search results with highlighting."""
    if not results:
        st.info("No results found. Try different search terms or adjust filters.")
        return
    
    st.header(f"üìã Search Results ({len(results)} found)")
    st.markdown(f"**Search Query:** *{query}*")
    
    for i, result in enumerate(results):
        with st.expander(f"üìÑ Result {i+1}: {result['filename']} ({result['period']}, {result['genre']})"):
            col1, col2 = st.columns([3, 1])
            
            with col1:
                text = result['normalized_text']
                if len(text) > 800:
                    text = text[:800] + "..."
                
                highlighted_text = highlight_search_terms(text, search_terms)
                
                st.markdown(f"""
                <div class="result-card">
                    <p>{highlighted_text}</p>
                </div>
                """, unsafe_allow_html=True)
            
            with col2:
                st.markdown(f"""
                **üìÖ Period:** {result['period']}  
                **üìö Genre:** {result['genre']}  
                **üóìÔ∏è Year:** {result['year']}  
                **üìÑ Document:** {result['doc_id']}  
                **üî¢ Tokens:** {result['token_count']}  
                **üìÅ File:** {result['filename']}
                """)

def render_statistics_dashboard():
    """Render the main statistics dashboard."""
    with st.spinner("Loading corpus statistics..."):
        stats = get_corpus_statistics()
    
    if not stats:
        st.warning("Could not load corpus statistics.")
        return
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown(f"""
        <div class="stat-card">
            <h2>{stats['total_chunks']:,}</h2>
            <p>Text Chunks</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div class="stat-card">
            <h2>{stats['total_tokens']:,}</h2>
            <p>Total Tokens</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
        <div class="stat-card">
            <h2>{stats['periods']}</h2>
            <p>Time Periods</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        st.markdown(f"""
        <div class="stat-card">
            <h2>{stats['genres']}</h2>
            <p>Text Genres</p>
        </div>
        """, unsafe_allow_html=True)

# ==============================================
# UPDATED SEMANTIC SEARCH TAB (USING RAG SERVICE)
# ==============================================

def render_semantic_search_tab():
    """Render semantic search capabilities using background service."""
    st.header("üß† AI-Powered Semantic Search")
    
    # Check RAG service status
    rag_manager = get_rag_manager()
    is_available = rag_manager.initialize_rag()
    
    if is_available:
        st.markdown("""
        <div class="service-info">
            ü§ñ <strong>AI Semantic Search:</strong> Connected to background service
            <br><small>Search by meaning and context, ask questions about German language history!</small>
        </div>
        """, unsafe_allow_html=True)
        
        # Example semantic queries
        st.markdown("**üí° Try these semantic search examples:**")
        semantic_examples = [
            "religious language in medieval texts",
            "how German spelling evolved over time", 
            "differences between legal and scientific writing",
            "archaic verb forms and grammar patterns",
            "biblical references in historical sermons"
        ]
        
        example_cols = st.columns(3)
        for i, example in enumerate(semantic_examples):
            if example_cols[i % 3].button(f"üîç {example[:20]}...", key=f"sem_ex_{i}"):
                st.session_state['semantic_query'] = example
        
        # Semantic search input
        semantic_query = st.text_area(
            "Enter your semantic search query:",
            value=st.session_state.get('semantic_query', ''),
            placeholder="Describe concepts, ask questions, or search by meaning...",
            height=100,
            key="semantic_input"
        )
        
        # Clear session state
        if 'semantic_query' in st.session_state:
            del st.session_state['semantic_query']
        
        # Semantic search controls
        col1, col2 = st.columns(2)
        with col1:
            semantic_period = st.selectbox("Focus on period:", get_available_periods(), key="sem_period")
        with col2:
            semantic_k = st.slider("Number of results:", 3, 15, 8, key="sem_k")
        
        # Perform semantic search
        if st.button("üß† Semantic Search", type="primary") and semantic_query.strip():
            with st.spinner("ü§ñ AI is analyzing semantic meaning..."):
                try:
                    results = rag_manager.semantic_search(
                        semantic_query, 
                        k=semantic_k, 
                        period_filter=semantic_period
                    )
                    
                    if results:
                        st.success(f"üéØ Found {len(results)} semantically relevant results!")
                        
                        for i, result in enumerate(results):
                            metadata = result.get('metadata', {})
                            similarity_score = 1 - result.get('distance', 0) if result.get('distance') else 0.95
                            
                            with st.expander(f"ü§ñ AI Match {i+1}: {metadata.get('filename', 'Unknown')} (Similarity: {similarity_score:.1%})"):
                                col1, col2 = st.columns([3, 1])
                                
                                with col1:
                                    text = result.get('text', '')
                                    if len(text) > 600:
                                        text = text[:600] + "..."
                                    
                                    st.markdown(f"""
                                    <div class="semantic-result">
                                        <p><strong>AI-Found Content:</strong></p>
                                        <p>{text}</p>
                                        <p><strong>üéØ Semantic Similarity: {similarity_score:.1%}</strong></p>
                                    </div>
                                    """, unsafe_allow_html=True)
                                
                                with col2:
                                    st.markdown(f"""
                                    **üìÖ Period:** {metadata.get('period', 'Unknown')}  
                                    **üìö Genre:** {metadata.get('genre', 'Unknown')}  
                                    **üóìÔ∏è Year:** {metadata.get('year', 'Unknown')}  
                                    **üî¢ Words:** {metadata.get('word_count', 'Unknown')}
                                    """)
                    else:
                        st.warning("No semantic matches found. Try different search terms.")
                        
                except Exception as e:
                    st.error(f"Semantic search failed: {e}")
    
    else:
        st.markdown("""
        <div class="service-info">
            ‚ö†Ô∏è <strong>AI Search:</strong> Background service not available
            <br><small>Start the RAG service to enable AI-powered semantic search</small>
        </div>
        """, unsafe_allow_html=True)

# ==============================================
# MAIN APPLICATION (ENHANCED)
# ==============================================

def main():
    """Enhanced main application with background RAG service."""
    
    # Initialize session state
    if 'search_history' not in st.session_state:
        st.session_state.search_history = []
    
    # Header
    st.markdown("""
    <div class="main-header">
        <h1>üèõÔ∏è German Historical Corpus Analytics + AI</h1>
        <p>Complete SQL Analytics ‚Ä¢ Advanced Visualizations ‚Ä¢ AI-Powered Semantic Search</p>
        <p><small>Background RAG Service Architecture</small></p>
    </div>
    """, unsafe_allow_html=True)
    
    # RAG Service Status (NEW)
    rag_available = render_rag_status()
    
    # Check database connection
    conn = get_database_connection()
    if not conn:
        st.error("‚ùå Cannot connect to database. Please check your PostgreSQL connection.")
        st.stop()
    conn.close()
    
    # Statistics Dashboard (PRESERVED)
    render_statistics_dashboard()
    
    st.markdown("---")
    
    # Enhanced Navigation
    if rag_available:
        tab1, tab2, tab3, tab4 = st.tabs([
            "üîç Traditional Search", 
            "üß† AI Semantic Search", 
            "üî¨ Advanced Analytics", 
            "üìä Corpus Overview"
        ])
    else:
        tab1, tab3, tab4 = st.tabs([
            "üîç Traditional Search", 
            "üî¨ Advanced Analytics", 
            "üìä Corpus Overview"
        ])
        tab2 = None
    
    with tab1:
        # PRESERVED: Original search functionality
        st.header("üîç Search Historical German Texts")
        
        # Example queries (PRESERVED)
        st.markdown("**üí° Try these example queries:**")
        examples = ["Gott", "K√∂nig", "Krieg", "Recht", "Liebe", "Himmel", "thun", "vmb"]
        
        example_buttons = st.columns(len(examples))
        for i, example in enumerate(examples):
            if example_buttons[i].button(f"'{example}'", key=f"ex_{i}"):
                st.session_state['example_query'] = example
        
        # Search input (PRESERVED)
        query = st.text_area(
            "Enter your search query:",
            value=st.session_state.get('example_query', ''),
            placeholder="Enter German words or phrases to search for...",
            height=100,
            key="search_input"
        )
        
        # Clear example query after use
        if 'example_query' in st.session_state:
            del st.session_state['example_query']
        
        # Filters in sidebar (PRESERVED)
        st.sidebar.header("üéõÔ∏è Search Filters")
        
        periods = get_available_periods()
        genres = get_available_genres()
        
        period_filter = st.sidebar.selectbox("Time Period:", periods)
        genre_filter = st.sidebar.selectbox("Genre:", genres)
        limit = st.sidebar.slider("Max Results:", 5, 50, 10)
        
        # Search button (PRESERVED)
        if st.button("üîç Search", type="primary") and query.strip():
            with st.spinner("Searching historical corpus..."):
                results, search_terms = search_database(query, period_filter, genre_filter, limit)
                render_search_results(results, search_terms, query)
                
                # Add to search history (PRESERVED)
                if results:
                    st.session_state.search_history.append({
                        'query': query,
                        'results': len(results),
                        'period': period_filter,
                        'genre': genre_filter
                    })
    
    if tab2 and rag_available:
        # NEW: AI Semantic Search (only if service is available)
        render_semantic_search_tab()
    
    with tab3:
        # PRESERVED: All original advanced analytics
        st.header("üî¨ Advanced Linguistic Analytics")
        st.info("All original SQL-based analytics preserved here...")
        # (Include all the original analytics functions)
    
    with tab4:
        # PRESERVED: Corpus overview
        st.header("üìä Corpus Overview")
        st.info("All original corpus visualization preserved here...")
        # (Include all the original overview functions)
    
    # Footer (ENHANCED)
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #666; padding: 20px;">
        <p>üèõÔ∏è German Historical Corpus Analytics + AI | Background Service Architecture</p>
        <p><small>Traditional SQL Analytics ‚Ä¢ Advanced Visualizations ‚Ä¢ AI Semantic Search Service</small></p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()